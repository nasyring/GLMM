[{"path":"index.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"","code":""},{"path":"intro.html","id":"intro","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"poisson-regression.html","id":"poisson-regression","chapter":"3 Poisson Regression","heading":"3 Poisson Regression","text":"","code":""},{"path":"poisson-regression.html","id":"children-ever-born-data","chapter":"3 Poisson Regression","heading":"3.1 Children Ever Born Data","text":"“Children Ever Born” (CEB) dataset consists grouped data number births Fijian women. women described according marriage duration ordinal levels: (1=0-4, 2=5-9, 3=10-14, 4=15-19, 5=20-24, 6=25-29); place residence (Suva, capital city; Urban; Rural); , level education (none, lower primary, upper primary, secondary greater). count, mean, variance number children ever born, group size, given group women cross-classified factorial level. summaries sufficient model counts children ever born Poisson distribution (individual woman’s count needed).CEB data example observational dataset — characteristics individuals inherent rather set experimenters experimental/controlled trial, clear context. Several interesting questions may answered using data, : fewer born children associated higher lower education among Fijian women; urban versus rural living location influence number children ever born; , number children ever born steadily increase marrige duration, tend plateau?statistician (student statistician) familiar multiple linear regression /ANOVA factorial experiments may instinctively choose fit Gauss-Markov linear model CEB data, treating responses independent normal random variables. However, since responses counts, Poisson model reasonable. , just one perform Poisson regression? — opposed familiar multiple linear regression described Gauss-Markov model:\n\\[Y = X\\beta+ \\epsilon, \\quad \\epsilon \\sim N_{n}(0_{n\\times 1}, \\sigma^2 I_n).\\]motivation chapter, explore family Generalized Linear Models defining fitting model, performing inference model diagnostics, within context CEB example.","code":"\nceb <- read.table('ceb.dat')\nhead(ceb)##   dur   res  educ mean  var  n     y\n## 1 0-4  Suva  none 0.50 1.14  8  4.00\n## 2 0-4  Suva lower 1.14 0.73 21 23.94\n## 3 0-4  Suva upper 0.90 0.67 42 37.80\n## 4 0-4  Suva  sec+ 0.73 0.48 51 37.23\n## 5 0-4 urban  none 1.17 1.06 12 14.04\n## 6 0-4 urban lower 0.85 1.59 27 22.95"},{"path":"poisson-regression.html","id":"defining-glms","chapter":"3 Poisson Regression","heading":"3.2 Defining GLMs","text":"CEB data naturally want model CEB grouped counts realizations Poisson r.v.’s means \\(n_{j}x^\\top_j\\beta\\) \\(n_j\\) number women \\(j^{\\text{th}}\\) factorial group, \\(x_j\\) vector common covariates, \\(\\beta\\) common regression coefficient vector. , likelihood model \n\\[L(\\beta;\\text{data}) = \\prod_{j=1}^{70}\\frac{(n_{j}x^\\top_j\\beta)^{y_j}e^{-n_{j}x^\\top_j\\beta}}{y_j!}\\]\nloglikelihood given \n\\[\\ell(\\beta;\\text{data}) = \\text{constant} + \\sum_{j=1}^{70}y_j\\log(n_{j}x^\\top_j\\beta) - n_{j}x^\\top_j\\beta.\\]\nPoisson likelihood member Exponential Family, contains distributions PDFs may expressed \n\\[f(y;\\theta,\\phi) = \\exp\\{[y\\theta - b(\\theta)]/(\\phi) + c(y,\\phi)\\}.\\]\nLooking ahead, apply exponential family model independent identically distributed responses, similar data encounter multiple linear regression Gauss-Markov model, allow \\(\\theta\\) well forms \\(\\), \\(b\\), \\(c\\) functions vary observations, fix \\(\\phi\\), loglikelihood sample size \\(n\\) may written follows:\n\\[\\ell(\\beta;\\text{data}) = \\sum_{=1}^n \\{[y_i\\theta_i - b_i(\\theta_i)]/a_i(\\phi) + c_i(\\phi, y_i)\\}.\\]\nPoisson regression model fairly simple member family, \\(\\theta = \\log (n_{j}x^\\top_j\\beta)\\), \\(\\phi = (\\phi) = 1\\), \\(b(\\theta) = \\exp(\\theta) =n_{j}x^\\top_j\\beta\\). fact, often case GLMs satisfy \\((\\phi)\\propto \\phi\\) known constant. \ngeneral, GLMs satisfy\n\\[E(Y) = b'(\\theta) \\quad \\text{}\\quad V(Y) = b''(\\theta)(\\phi).\\]\nPoisson regression model, particular, \n\\[E(Y) = b'(\\theta) = \\frac{\\partial}{\\partial \\theta}\\exp(\\theta) = \\exp(\\theta) = n_{j}x^\\top_j\\beta; \\text{ ,}\\]\n\\[V(Y) = b''(\\theta)(\\phi) = \\frac{\\partial^2}{\\partial \\theta^2}\\exp(\\theta) = \\exp(\\theta) = n_{j}x^\\top_j\\beta.\\]","code":""},{"path":"poisson-regression.html","id":"fitting-glms","chapter":"3 Poisson Regression","heading":"3.3 Fitting GLMs","text":"Like model defined likelihood, GLMs may fit maximizing (log)likelihood. , generally case maximizers (MLEs) available closed form. Instead, computed iteratively using Newton’s method similar iterative procedure. Refer exponential family loglikelihood using usual representation \\(a_i(\\phi) = \\phi/w_i\\) \\(w_i\\) known constants:\n\\[\\ell(\\beta;\\text{data}) = \\sum_{=1}^n \\{w_i[y_i\\theta_i - b_i(\\theta_i)]/\\phi + c_i(\\phi, y_i)\\}.\\]\nWrite \\(g(\\mu_i) = x_i^\\top\\beta\\) \\(\\mu_i\\) mean response \\(Y_i\\) \\(g\\) “link function” determines transformation mean linear covariates; example, Poisson regression model, \\(\\log \\mu_j = n_jx_j^\\top \\beta\\) link function logarithm. Since \\(b_i'(\\theta_i)\\) also equal \\(\\mu_i\\) exponential family, may differentiate loglikelihood respect regression parameter \\(\\beta\\) using chain rule:\n\\[\\frac{\\partial \\ell}{\\partial \\beta_j} = \\sum_{=1}^n \\left\\{\\frac{w_i}{\\phi}\\left[y_i\\frac{\\partial \\theta_i}{\\partial\\beta_j} - \\frac{\\partial b_i(\\theta_i)}{\\partial \\beta_j}\\right] + c_i(\\phi, y_i)\\right\\}\\]\nusing\n\\[\\frac{\\partial \\theta_i}{\\partial \\beta_j} = \\frac{\\partial \\theta_i}{\\partial \\mu_i}\\frac{\\partial \\mu_i}{\\partial \\beta_j}.\\]\nSince \\(\\mu_i = b_i'(\\theta_i)\\) \\(\\partial \\theta_i/\\partial \\mu_i = 1/b_i''(\\theta_i)\\). , since \\(\\mu_i = g^{-1}(x_i^\\top \\beta)\\) \\(\\partial\\mu_i/\\partial \\beta_j = x_{ij}/g'[g^{-1}(x_i^\\top \\beta)]\\). Substituting, can wire score function using \\(\\mu_i\\) follows:\n\\[\\frac{\\partial \\ell}{\\partial \\beta_j} = \\frac{1}{\\phi}\\sum_{=1}^n \\frac{y_i - \\mu_i}{g'(\\mu_i)V(\\mu_i)}x_{ij}.\\]\nsecond (mixed partial) derivative may written\n\\[\\frac{\\partial^2 \\ell}{\\partial \\beta_j\\partial\\beta_k} = -\\frac{1}{\\phi}\\sum_{=1}^n \\frac{x_{ij}x_{ik}h(\\mu_i)}{g'(\\mu_i)^2V(\\mu_i)}\\]\n\\(h(\\mu_i) = 1+(y_i-\\mu_i)\\{V'(\\mu_i)/V(\\mu_i) + g''(\\mu_i)/g'(\\mu_i)\\}\\). expectation second derivative (multiplied -1 appears Fisher information matrix) quantity \\(h(\\mu_i)\\) replaced \\(E[h(\\mu_i)]\\), simply equals 1 \\(E(Y_i - \\mu_i) = 0\\).\nHessian loglikelihood clearly quadratic form \\(\\phi^{-1}X^\\top WX\\) \\(X\\) \\(n\\times p\\) design matrix covariates \\(W = [h(\\mu_i)/\\{g'(\\mu_i)^2V(\\mu_i)\\}]\\) \\(n\\times n\\) diagonal matrix “weights”. Less obvious, may define \\(G = \\text{diag}\\{g'(\\mu_i)/h(\\mu_i)\\}\\) gradient loglikelihood equals \\(\\phi^{-1}X^\\top WG(y - \\mu)\\). clever rewriting, Newton’s method updates take form weighted least squares solution:\n\\[\\begin{align*}\n\\beta^{[k+1]} &= \\beta^{[k]} + (X^\\top WX)^{-1}X^\\top WG(y-\\mu)\\\\\n& = (X^\\top WX)^{-1}X^\\top W\\{G(y-\\mu)X+\\beta^{[k]}\\}\\\\\n& = (X^\\top WX)^{-1}X^\\top Wz\n\\end{align*}\\]\n\\(z := G(y-\\mu)X\\beta^{[k]}\\) sometimes referred “pseudo-data”. Repeating weighted least squares update, iteratively, convergence, termed iteratively re-weighted least squares (IRLS) since, course, weights \\(W\\) updating iteration.Poisson regression based grouped CEB data following likelihood, gradient, Hessian:\n\\[\\begin{align*}\n&\\ell(\\beta;\\text{data}) = \\sum_{j=1}^{70} \\left[y_j x_j^\\top \\beta - n_j e^{x_j^\\top \\beta}\\right]\\\\\n&\\nabla_s \\ell = \\sum_{j=1}^{70} \\left[y_j x_{js} - n_j x_{js}e^{x_j^\\top \\beta}\\right]\\\\\n&\\nabla^2_{s,t} \\ell = -\\sum_{j=1}^{70}  n_j x_{js}x_{jt}e^{x_j^\\top \\beta}.\n\\end{align*}\\]Rewriting Hessian gradient general exponential family GLM \n\\[W_{k,k} = n_k\\mu_k\\quad\\text{}\\quad G_k = (n_k\\mu_k)^{-1}\\]\nIRLS updates given \n\\[(X^\\top WX)^{-1}X^\\top Wz\\]\n\\(z_k = (n_k\\mu_k)^{-1}(y_k - n_k\\mu_k) + x_k^\\top \\beta\\).","code":""},{"path":"poisson-regression.html","id":"irls-for-the-ceb-data","chapter":"3 Poisson Regression","heading":"3.3.1 IRLS for the CEB data","text":"","code":"\nn <- nrow(ceb)\ngroup.sizes <- ceb$n\nY <- ceb$y\n# IRLS - factor coding\n# initialize with mu = Y/group.sizes\noptions(contrasts = c('contr.treatment', 'contr.treatment'))\nX <- model.matrix(y~dur+res+educ, data = ceb)\nmu <- Y/group.sizes\nXB <- log(mu)\nW <- diag(as.numeric(mu))\nz <- -(1/mu)*(Y/group.sizes-mu) + XB\nbeta <- solve(t(X)%*%W%*%X)%*%t(X)%*%W%*%z\ntol <- 0.0001\ndifference <- 1\nmaxiter <- 100\niter <- 1\nwhile((difference > tol) & (iter < maxiter)){\n  XB <- X%*%beta\n  mu <- exp(XB)\n  W <- diag(as.numeric(group.sizes*mu))\n  z <- (Y/diag(W) - rep(1,n)) + XB\n  beta.old <- beta\n  beta <- solve(t(X)%*%W%*%X)%*%t(X)%*%W%*%z\n  difference <- max(abs(beta - beta.old))\n  iter<-iter+1\n}\nbeta##                    [,1]\n## (Intercept)  0.05695417\n## dur10-14     1.37053208\n## dur15-19     1.61423104\n## dur20-24     1.78548879\n## dur25-29     1.97679469\n## dur5-9       0.99765038\n## resSuva     -0.15121728\n## resurban    -0.03895822\n## educnone    -0.02308034\n## educsec+    -0.33266474\n## educupper   -0.12474575\n## the glm function can be used with offset equal to logarithm of the group sizes\nsummary(glm(round(y)~dur+res+educ, family = poisson(link = 'log'), data = ceb, offset = log(n)))## \n## Call:\n## glm(formula = round(y) ~ dur + res + educ, family = poisson(link = \"log\"), \n##     data = ceb, offset = log(n))\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -2.2960  -0.6641   0.0725   0.6336   3.6782  \n## \n## Coefficients:\n##             Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)  0.05754    0.04803   1.198    0.231    \n## dur10-14     1.36940    0.05107  26.815  < 2e-16 ***\n## dur15-19     1.61376    0.05119  31.522  < 2e-16 ***\n## dur20-24     1.78491    0.05121  34.852  < 2e-16 ***\n## dur25-29     1.97641    0.05003  39.501  < 2e-16 ***\n## dur5-9       0.99693    0.05274  18.902  < 2e-16 ***\n## resSuva     -0.15166    0.02833  -5.353 8.63e-08 ***\n## resurban    -0.03924    0.02463  -1.594    0.111    \n## educnone    -0.02297    0.02266  -1.014    0.311    \n## educsec+    -0.33312    0.05390  -6.180 6.41e-10 ***\n## educupper   -0.12425    0.03000  -4.142 3.44e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 3731.852  on 69  degrees of freedom\n## Residual deviance:   70.665  on 59  degrees of freedom\n## AIC: 522.14\n## \n## Number of Fisher Scoring iterations: 4"}]
