<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 Linear Mixed Models | GLMM</title>
<meta name="author" content="Nick Syring">
<meta name="description" content="4.1 ANOVA with random factors The simplest linear mixed models are used to analyze linear models for one-way ANOVA, randomized complete block designs, and two-way ANOVA. Mixed models as opposed to...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 4 Linear Mixed Models | GLMM">
<meta property="og:type" content="book">
<meta property="og:description" content="4.1 ANOVA with random factors The simplest linear mixed models are used to analyze linear models for one-way ANOVA, randomized complete block designs, and two-way ANOVA. Mixed models as opposed to...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 Linear Mixed Models | GLMM">
<meta name="twitter:description" content="4.1 ANOVA with random factors The simplest linear mixed models are used to analyze linear models for one-way ANOVA, randomized complete block designs, and two-way ANOVA. Mixed models as opposed to...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">GLMM</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="" href="poisson-regression.html"><span class="header-section-number">3</span> Poisson Regression</a></li>
<li><a class="active" href="linear-mixed-models.html"><span class="header-section-number">4</span> Linear Mixed Models</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="linear-mixed-models" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Linear Mixed Models<a class="anchor" aria-label="anchor" href="#linear-mixed-models"><i class="fas fa-link"></i></a>
</h1>
<div id="anova-with-random-factors" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> ANOVA with random factors<a class="anchor" aria-label="anchor" href="#anova-with-random-factors"><i class="fas fa-link"></i></a>
</h2>
<p>The simplest linear mixed models are used to analyze linear models for one-way ANOVA, randomized complete block designs, and two-way ANOVA. <em>Mixed</em> models as opposed to <em>fixed</em> models (the linear models you have heretofore studied) are needed when factors have levels that are <strong>random</strong>. Random levels occur whenever the units making up those levels behave like random samples from a population. Two examples are given below. And, we discuss how to perform ANOVA-like tests for factors that are random rather than fixed. The upshot is that (at least for balanced experiments/datasets) the tests for fixed effects are identical to those for random effects, only the interpretation is different (and importantly so!).</p>
<div id="strength-of-metallic-bonds" class="section level3" number="4.1.1">
<h3>
<span class="header-section-number">4.1.1</span> Strength of metallic bonds<a class="anchor" aria-label="anchor" href="#strength-of-metallic-bonds"><i class="fas fa-link"></i></a>
</h3>
<p>The dataset below, called “Bonds”, contains responses for 21 samples of metals, 7 each for iron, nickel, and copper, that quantify the strength of metallic bonds. One sample from each metal was extracted from each of 7 ingots. We expect ingots to act like blocks—differences in ingots account for a substantial amount of variability in the responses, but the precise block effects are of no inferential/scientific inference. We only include the blocks in order to reduce the residual variance after accounting for block variance. A randomized controlled block design describes how this data was collected, but, if we repeated the experiment, the blocks (ingots) would be completely different. That is, the blocks are not <em>fixed</em> but <em>random</em>. Rather than estimating block effects that would surely change experiment to experiment, we should focus on estimating the amount of variability explained by the blocks, which should remain about the same experiment to experiment. This suggests a different model than used to analyze RCBD experiments with fixed blocks.<br><br></p>
<p>The usual linear model for fixed blocks is
<span class="math display">\[y_{ijk} = \mu + \alpha_i + \beta_j + \epsilon_{ij},\]</span>
where <span class="math inline">\(y_{ij}\)</span> is the response for treatment (metal) <span class="math inline">\(i\)</span> in block (ingot) <span class="math inline">\(j\)</span>; the <span class="math inline">\(\alpha_i\)</span>’s are the metal (treatment) effects; the <span class="math inline">\(\beta_j\)</span>’s are the ingot (block) effects; and, <span class="math inline">\(\epsilon_{ij}\stackrel{iid}{\sim}N(0,\sigma^2)\)</span> are the random residuals.<br><br></p>
<p>The above linear model is the wrong model for this data because the block effects (and, hence, also the interaction effects) are meaningless outside of the given data set; these are not population-level parameters because the blocks are random rather than fixed. The appropriate model (given normality and independence of random residuals is reasonable) is the following <em>mixed effects model</em>:</p>
<p><span class="math display" id="eq:fullmodel">\[\begin{equation}
y_{ij} = \mu + \alpha_i + \beta_j + \epsilon_{ij},
\tag{4.1}
\end{equation}\]</span>
where <span class="math inline">\(\beta_j\stackrel{iid}{\sim}N(0, \sigma_b^2)\)</span> and, independently, <span class="math inline">\(\epsilon_{ij}\stackrel{iid}{\sim}N(0,\sigma^2)\)</span>. <br><br></p>
<p>For <em>balanced</em> experiments (the number of replicates is equal across each combination of factor levels) we can test for block and treatment effects by comparing nested/aggregated models. Let <span class="math inline">\(\overline Y_{i\cdot}\)</span> denote the mean response for metal <span class="math inline">\(i\)</span> averaged over ingots. We can write down the following aggregated model from <a href="linear-mixed-models.html#eq:fullmodel">(4.1)</a> as
<span class="math display" id="eq:aggmodel1">\[\begin{equation}
\overline y_{i\cdot} = \mu + \alpha_i + \epsilon_{i},
\tag{4.2}
\end{equation}\]</span>
where <span class="math inline">\(\epsilon_i = \frac{1}{J}\sum_{j=1}^j \epsilon_{ij}\)</span>. Then, <span class="math inline">\(\epsilon_j\)</span> has variance <span class="math inline">\(\sigma_b^2 + \sigma^2/J\)</span>. The F statistic
<span class="math display">\[F = \frac{J\cdot MSE_{agg}}{MSE_{full}}\]</span>
where <span class="math inline">\(MSE_{agg}\)</span> and <span class="math inline">\(MSE_{full}\)</span> are the mean squared errors from the models in <a href="linear-mixed-models.html#eq:aggmodel1">(4.2)</a> and <a href="linear-mixed-models.html#eq:fullmodel">(4.1)</a> can be used to test the hypothesis <span class="math inline">\(H_0:\sigma_b^2 = 0\)</span>.</p>
</div>
<div id="machine-productivity" class="section level3" number="4.1.2">
<h3>
<span class="header-section-number">4.1.2</span> Machine productivity<a class="anchor" aria-label="anchor" href="#machine-productivity"><i class="fas fa-link"></i></a>
</h3>
<p>The dataset given below contains the results of a designed experiment to evaluate worker productivity using 3 different industrial machines. The goal is to determine which machine is most productive while controlling for natural variation in worker productivity. The observed workers represent a random sample from a population of workers (blocks), analogous to the ingots in the previous example. The difference between the two examples (besides the context) is that the machine treatments are replicated wihtin workers, so that there are three observations of a productivity score fore each worker for each type of machine. This means that we can fit a model with <em>interaction terms</em> capable of capturing changes in machine effects on productivity between different workers (if those changes are present):
<span class="math display" id="eq:fullmodel2">\[\begin{equation}
y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk},
\tag{4.3}
\end{equation}\]</span>
where <span class="math inline">\(k\)</span> denotes the <span class="math inline">\(k^{\text{th}}\)</span> replicate within machine <span class="math inline">\(i\)</span> and worker <span class="math inline">\(j\)</span>; and where <span class="math inline">\((\alpha\beta)_{ij}\)</span> denote the machine-worker interaction effects. <br><br></p>
<p>Let <span class="math inline">\(\overline Y_{ij\cdot}\)</span> be the mean response averaging over replicates for the treatment <span class="math inline">\(i\)</span> and block <span class="math inline">\(j\)</span> combination. Then,
<span class="math display">\[\begin{align*}
V(\overline Y_{ij\cdot}) &amp;= V\left(K^{-1}\sum_{k=1}^K Y_{ijk}\right) \\
&amp;= \frac{1}{K^2}V\left(\sum_{k=1}^K \{\mu+\alpha_i+\beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk}\}\right)\\
&amp; = \frac{1}{K^2}V\left(K\mu + K\alpha_i + K\beta_j + K(\alpha\beta)_{ij} + \sum_{k=1}^K \epsilon_{ijk}\right)\\
&amp; = \sigma_b^2 + \sigma_{ab}^2 + K^{-1}\sigma^2.
\end{align*}\]</span>
If we rewrite the model for the cell mean responses as
<span class="math display" id="eq:aggmodel">\[\begin{equation}
\overline y_{ij\cdot} = \mu + \alpha_i + \beta_j + \epsilon_{ij},
\tag{4.4}
\end{equation}\]</span>
then the aggregated error term follows <span class="math inline">\(\epsilon_{ij}\stackrel{iid}{\sim}N(0, \sigma_{ab}^2 + \sigma^2/K)\)</span>. The residual mean square (or called the mean squared error) of model <a href="linear-mixed-models.html#eq:fullmodel2">(4.3)</a> (let’s call it <span class="math inline">\(MSE_{\text{full}}\)</span>) has mean <span class="math inline">\(\sigma^2\)</span> with <span class="math inline">\(n-p_1\)</span> degrees of freedom where <span class="math inline">\(n\)</span> is the sample size and <span class="math inline">\(p\)</span> is the number of coefficients in the fitted model (<span class="math inline">\(p_1\)</span> equals the number of crossed factor levels, the number of blocks times the number of treatments). The residual mean square for the aggregated model in <a href="linear-mixed-models.html#eq:aggmodel">(4.4)</a> (let’s call it <span class="math inline">\(MSE_{\text{agg}}\)</span>) has mean <span class="math inline">\(\sigma_{ab}^2 + \sigma^2/K\)</span> with <span class="math inline">\(n/K-p_2\)</span> degrees of freedom where <span class="math inline">\(p_2\)</span> is the number of treatments plus the number of blocks minus 1. An unbiased estimate of <span class="math inline">\(\sigma_{ab}^2\)</span> is given by <span class="math inline">\(MSE_{\text{agg}} - \frac{1}{K}MSE_{\text{full}}\)</span>. Consider testing the null hypothesis <span class="math inline">\(H_0:\sigma_{ab}^2 = 0\)</span>. The statistic
<span class="math display">\[F := \frac{K\cdot MSE_{agg}}{MSE_{full}}\stackrel{H_0}{\sim}F_{n/K-p_2, n-p_1},\]</span>
that is, under the null hypothesis. The test that rejects <span class="math inline">\(H_0\)</span> for <span class="math inline">\(F &gt; F_{1-\alpha,n/K-p_2, n-p_1}\)</span> is exactly equivalent to the partial F test between the full model and the full model without the interaction terms (the additive model). <br><br></p>
<p>Below we use R to compute ANOVA tables for the full model, full model without interaction, and the aggregated model. The F test statistic for the aggregated model is about 46.13 on 10 and 36 degrees of freedom, which exactly matches the partial F test between the full and additive models.</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://svn.r-project.org/R-packages/trunk/nlme/">nlme</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># aggregated model</span></span>
<span><span class="va">Mach.agg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aggregate.html">aggregate</a></span><span class="op">(</span><span class="va">score</span><span class="op">~</span><span class="va">Machine</span><span class="op">*</span><span class="va">Worker</span>, data <span class="op">=</span> <span class="va">Machines</span>, FUN<span class="op">=</span><span class="va">mean</span><span class="op">)</span></span>
<span></span>
<span><span class="va">m2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">score</span><span class="op">~</span><span class="va">Machine</span><span class="op">+</span><span class="va">Worker</span>, data <span class="op">=</span> <span class="va">Mach.agg</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: score
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Machine    2 585.09 292.544 20.5761 0.0002855 ***
## Worker     5 413.97  82.793  5.8232 0.0089495 ** 
## Residuals 10 142.18  14.218                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># full model with interaction</span></span>
<span><span class="va">m0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">score</span><span class="op">~</span><span class="va">Machine</span><span class="op">*</span><span class="va">Worker</span>, data <span class="op">=</span> <span class="va">Machines</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">m0</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: score
##                Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## Machine         2 1755.26  877.63  949.17 &lt; 2.2e-16 ***
## Worker          5 1241.89  248.38  268.63 &lt; 2.2e-16 ***
## Machine:Worker 10  426.53   42.65   46.13 &lt; 2.2e-16 ***
## Residuals      36   33.29    0.92                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">142.18</span><span class="op">*</span><span class="fl">3</span><span class="op">/</span><span class="fl">10</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fl">33.29</span><span class="op">/</span><span class="fl">36</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 46.12628</code></pre>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">pf</a></span><span class="op">(</span><span class="op">(</span><span class="fl">142.18</span><span class="op">*</span><span class="fl">3</span><span class="op">/</span><span class="fl">10</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fl">33.29</span><span class="op">/</span><span class="fl">36</span><span class="op">)</span>, <span class="fl">10</span>, <span class="fl">36</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># additive model (no interaction)</span></span>
<span><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">score</span><span class="op">~</span><span class="va">Machine</span><span class="op">+</span><span class="va">Worker</span>, data <span class="op">=</span> <span class="va">Machines</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: score
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## Machine    2 1755.26  877.63  87.798 &lt; 2.2e-16 ***
## Worker     5 1241.89  248.38  24.848 4.867e-12 ***
## Residuals 46  459.82   10.00                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">m1</span>,<span class="va">m0</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: score ~ Machine + Worker
## Model 2: score ~ Machine * Worker
##   Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)    
## 1     46 459.82                                 
## 2     36  33.29 10    426.53 46.13 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div id="a-general-linear-mixed-model" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> A general linear mixed model<a class="anchor" aria-label="anchor" href="#a-general-linear-mixed-model"><i class="fas fa-link"></i></a>
</h2>
<p>For experiments comparing responses between factors the ANOVA-type analyses above are sufficient. But, for more general models with random effects, e.g., those including continuous covariates, general-purpose methods are needed. The general mixed effects model may be written
<span class="math display">\[Y = X\beta+ Z\alpha + \epsilon\]</span>
where Y is an <span class="math inline">\(n\times 1\)</span> response, <span class="math inline">\(X\)</span> is an <span class="math inline">\(n \times p\)</span> design matrix for fixed (non-random) effects; <span class="math inline">\(Z\)</span> is and <span class="math inline">\(n\times a\)</span> matrix for random effects; <span class="math inline">\(\beta\)</span> is a <span class="math inline">\(p\times 1\)</span> non-random coefficient vector; <span class="math inline">\(\alpha\sim N_a(0, \psi_\theta)\)</span> is an <span class="math inline">\(a\times 1\)</span> multivariate normal random coefficient vector with mean 0 and covariance matrix <span class="math inline">\(\psi_\theta\)</span> indexed by a parameter <span class="math inline">\(\theta\)</span>; and <span class="math inline">\(\epsilon\sim N_n(0, \Lambda_\theta)\)</span> is a multivariate normal random residual vector with covariance matrix <span class="math inline">\(\Lambda_\theta\)</span>. An alternative way of writing the model (quite succintly) is
<span class="math display" id="eq:linmix">\[\begin{equation}
\tag{4.5}
Y\sim N_n(X\beta, Z \psi_\theta Z^\top + \Lambda_\theta).
\end{equation}\]</span>
For abbreviation we will denote <span class="math inline">\(\Sigma = Z \psi_\theta Z^\top + \Lambda_\theta\)</span> and we will often drop <span class="math inline">\(\theta\)</span> from <span class="math inline">\(\psi\)</span> and <span class="math inline">\(\Lambda\)</span> to save pixels.<br>
### Parameter estimation using PML</p>
<p>The linear mixed model in <a href="linear-mixed-models.html#eq:linmix">(4.5)</a> may be fit using maximum likelihood estimation (MLE), but the (potentially) complicated covariance structure poses challenges to numerical maximization of the likelihood function. Rather than straightforward MLE, linear mixed models are usually fit using either <em>restricted maximum likelihood estimation</em> (REML, also called residual MLE) or <em>profile maximum likelihood estimation</em> (PML). Both approaches aim to simplify the computation of the maximum while retaining the good asymptotic properties of maximum likelihood estimators. While MLE is a frequentist concept, it turns out that REML can be derived most intuitively using a Bayesian approach.</p>
<p>If you have previously covered general linear models, i.e., <span class="math inline">\(Y = X\beta + \epsilon\)</span> where <span class="math inline">\(Cov(\epsilon) = W\)</span> for some known <span class="math inline">\(W\)</span> or equals <span class="math inline">\(\sigma^2 W\)</span> for an unknown scalar <span class="math inline">\(\sigma^2\)</span> and a known matrix <span class="math inline">\(W\)</span>, then you are familiar with weighted least squares (WLS) estimation. Often weighted least squares is employed in response to observed heteroskedasticity in residuals related to covariates so that <span class="math inline">\(W\)</span> depends on covariate values. If the linear mixed model covariance parameter <span class="math inline">\(\theta\)</span> were known, then the model could be fit using WLS:
<span class="math display">\[\hat\beta(\theta) = (X^\top \Sigma^{-1}X)^{-1}X^\top \Sigma^{-1}Y\]</span>
just as in other applications of weighted least squares.</p>
<p>The above WLS solution inspires the PML technique: maximize the likelihood with respect to <span class="math inline">\(\theta\)</span> after plugging in <span class="math inline">\(\beta = \hat\beta(\theta)\)</span>. PML reproduces MLEs exactly; its advantage is its simplified formulation of the likelihood maximization problem.</p>
<p>Nevertheless there are two problems with the PML strategy suggested above: one computational and the other statistical.</p>
<p>The first problem is that PML/WLS requires inverting the <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(\Sigma\)</span>. For even moderate sample sizes this matrix inversion can be both computationally demanding and computationally unstable. Fortunately, some clever linear algebra resolves this problem. Define matrix <span class="math inline">\(A:=\psi^{-1} + Z^\top \Lambda^{-1}Z\)</span>. Observe that the matrix <span class="math inline">\(\Lambda^{-1} - \Lambda^{-1}ZA^{-1}Z^\top \Lambda^{-1}\)</span> equals the inverse of <span class="math inline">\(Z\psi Z^\top + \Lambda\)</span>:
<span class="math display">\[\begin{align*}
&amp;(\Lambda^{-1} - \Lambda^{-1}ZA^{-1}Z^\top \Lambda^{-1})(Z\psi Z^\top + \Lambda) \\
&amp; = \Lambda^{-1}Z\psi Z^\top + I - \Lambda^{-1}ZA^{-1}Z^\top \Lambda^{-1}Z\psi Z^\top - \Lambda^{-1}ZA^{-1}Z^\top \\
&amp; = I + \Lambda^{-1}Z(\psi - A^{-1}(Z^\top \Lambda^{-1}Z\psi + I))Z^\top \\
&amp; = I+\Lambda^{-1}Z(\psi - \psi(Z^\top \Lambda^{-1}A\psi + I)^{-1}(Z^\top \Lambda^{-1}A\psi + I))Z^\top \\
&amp; = I
\end{align*}\]</span>
The key property of this inverse is that it only requires computing the inverse of <span class="math inline">\(p\times p\)</span> and <span class="math inline">\(a\times a\)</span> matrices, and does not require the computation of any <span class="math inline">\(n\times n\)</span> matrix inverse. In many practical applications both <span class="math inline">\(p\)</span> and <span class="math inline">\(a\)</span> are much smaller than <span class="math inline">\(n\)</span>, and the matrices <span class="math inline">\(\Lambda\)</span> and <span class="math inline">\(\psi\)</span> often have simple/sparse structures with many exact zeroes, so that the above matrix inversions may be performed very quickly and reliably.</p>
<p>The second issue with PML cannot as easily be overcome. Think back to the Gauss-Markov model <span class="math inline">\(Y = X\beta+\epsilon\)</span> where <span class="math inline">\(Cov(\epsilon) = \sigma^2 I_n\)</span>. Recall that the MLE <span class="math inline">\(\hat\sigma^2\)</span> is biased, i.e., <span class="math inline">\(E(\hat\sigma^2) = \frac{n-p}{n}\sigma^2\)</span>. In practice we may have a substantial number of covariates relative to sample size so that this bias can be quite significant; and, importantly, the bias results in an underestimate which causes over-optimism with respect to inferences concerning <span class="math inline">\(\beta\)</span>. The same phenomenon occurs in ML/PML estimation: the PML estimate of <span class="math inline">\(\theta\)</span> is biased. The desire for an estimation strategy that constructively produces less-biased estimates of covariance parameters is the motivation for REML, covered next.</p>
<div id="reml---frequentist-approach" class="section level3" number="4.2.1">
<h3>
<span class="header-section-number">4.2.1</span> REML - frequentist approach<a class="anchor" aria-label="anchor" href="#reml---frequentist-approach"><i class="fas fa-link"></i></a>
</h3>
<p>There are two formulations both leading to the residual (also called restricted/reduced) maximum likelihood approach (REML), one frequentist (non-Bayesian) and the other Bayesian. Let’s explore both approaches.</p>
<p>The motivation for REML is to produce unbiased (or at least less biased than MLE) estimates of the covariance parameters. The REML approach to doing this may be interpreted as a likelihood approach based on residuals, or as a marginal likelihood approach to covariance parameter estimation.</p>
<p>Begin with the linear mixed model in <a href="linear-mixed-models.html#eq:linmix">(4.5)</a>. Assume <span class="math inline">\(X\)</span> has full rank <span class="math inline">\(p\)</span> and let <span class="math inline">\(L = [L_1 \,\,L_2]\)</span> denote a block matrix of <span class="math inline">\(n\times p\)</span> and <span class="math inline">\(n\times (n-p)\)</span> blocks with the properties
<span class="math display">\[L_1^\top X = I_p \quad\text{and}\quad L_2^\top X = 0_{n-p},\]</span>
such that <span class="math inline">\(L\)</span> has full rank <span class="math inline">\(n\)</span>.</p>
<p>This setup is a bit abstract, so it helps to find at least one concrete example of such an <span class="math inline">\(L\)</span>. Start with the projection matrix <span class="math inline">\(P_X := X(X^\top X)^{-1}X^\top\)</span>. Since <span class="math inline">\(P_X\)</span> is a symmetric, idempotent matrix of rank <span class="math inline">\(p\)</span> its eignevalues can only be zero or one, and, the number of eigenvalues (called multiplicity) of value one is equal to its rank, exactly <span class="math inline">\(p\)</span>. In addition, its eigenvectors are orthonormal. Hence,
<span class="math display">\[P_X = \begin{bmatrix}V_1 &amp; V_2\\
V_3 &amp;V_4\end{bmatrix}\begin{bmatrix}1_{p\times p} &amp; 0_{p\times n-p}\\
0_{n-p \times p} &amp; 0_{n-p \times n-p}\end{bmatrix}\begin{bmatrix}V_1 &amp; V_2\\
V_3 &amp;V_4\end{bmatrix}^\top.\]</span>
It follows from this representation that
<span class="math display">\[P_X = \begin{bmatrix}V_1 \\
V_3\end{bmatrix}\begin{bmatrix}V_1 \\
V_3 \end{bmatrix}^\top=:L_1L_1^\top\]</span>
Furthermore, if <span class="math inline">\(v\)</span> is an eigenvector of <span class="math inline">\(P_X\)</span> with eigenvalue 1, then <span class="math inline">\(v\)</span> is an eigenvector of <span class="math inline">\(I-P_X\)</span> with eigenvalue 0 just by the definition of an eigenvalue (<span class="math inline">\(Av=\lambda v\)</span>). It follows that
<span class="math display">\[I-P_X = \begin{bmatrix}V_2 \\
V_4\end{bmatrix}\begin{bmatrix}V_2 \\
V_4 \end{bmatrix}^\top=:L_2 L_2^\top.\]</span>
By construction, <span class="math inline">\(L_1L_2^\top = 0\)</span>, <span class="math inline">\(L_1^\top L_1 = I_p\)</span> and <span class="math inline">\(L_2^\top L_2 = I_{n-p}\)</span>. The columns of <span class="math inline">\(L\)</span> are orthogonal, and so <span class="math inline">\(L\)</span> is full rank.</p>
<p>In what follows, note that the REML estimates are invariant to the choice of <span class="math inline">\(L\)</span>, so long as it has the above three properties.</p>
<p>Now, consider the full rank linear transformation <span class="math inline">\(Y \mapsto LY = [Y_1 \quad Y_2]^\top\)</span>. By the properties of <span class="math inline">\(L\)</span>, we have
<span class="math display">\[LY = \begin{bmatrix} Y_1\\Y_2 \end{bmatrix} \sim N\left(\begin{bmatrix} \beta \\ 0\end{bmatrix}, \begin{bmatrix} L_1^\top \Sigma L_1 &amp;L_1^\top \Sigma L_2\\ L_2^\top \Sigma L_1 &amp; L_2^\top \Sigma L_2 \end{bmatrix}\right)\]</span>
where <span class="math inline">\(\Sigma = Cov(Y) = Z \psi_\theta Z^\top + \Lambda_\theta\)</span>.</p>
<p>The next step is to consider an equivalent characterization of the distribution of <span class="math inline">\((Y_1, Y_2)\)</span> as the product of the conditional distribution of <span class="math inline">\(Y_1|Y_2 = y_2\)</span> and the marginal distribution of <span class="math inline">\(Y_2\)</span>. Using the general formulas for the conditional distribution of a multivariate normal random vector, we get
<span class="math display">\[Y_1|y_2 \sim N(\beta - L_1^\top \Sigma L_2(L_2^\top \Sigma L_2)^{-1}y_2, \, L_1^\top \Sigma L_1-L_1^\top \Sigma L_2(L_2^\top \Sigma L_2)^{-1} L_2^\top \Sigma L_1).\]</span>
Some tedious linear algebra (omitted here) can be used to show that the above covariance matrix is actually equal to <span class="math inline">\((X^\top \Sigma^{-1}X)^{-1}\)</span>, regardless of the specific choice of <span class="math inline">\(L\)</span>.</p>
<p>Therefore, the conditional likelihood is given by
<span class="math display">\[\ell_c := \text{const.} - \tfrac12\log |(X^\top \Sigma^{-1}X)^{-1}| -\tfrac{1}{2}(y_1 - \beta - y_2^\star)X^\top \Sigma^{-1}X(y_1 - \beta - y_2^\star)^\top, \]</span>
where <span class="math inline">\(y_2^\star = L_1^\top \Sigma L_2(L_2^\top \Sigma L_2)^{-1}y_2\)</span>.</p>
<p>Again, some tedious linear algebra computations can be used to show that
<span class="math display">\[L_2(L_2^\top \Sigma L_2)^{-1}L_2^\top = \Sigma^{-1} - \Sigma^{-1}X(X^\top\Sigma^{-1} X)^{-1} X^\top\Sigma^{-1},\]</span>
which may be computed efficiently using the equivalent form of <span class="math inline">\(\Sigma^{-1}\)</span> given above. Furthermore, the block matrix determinant identity given by
<span class="math display">\[det\begin{bmatrix}A &amp; B\\
B^\top &amp; C\end{bmatrix} = |C||A - B^\top C^{-1}B|,\]</span>
applied to <span class="math inline">\(L^\top\Sigma L\)</span> can be used to show that
<span class="math display">\[\log |L_2^\top \Sigma L_2| = \log|L^\top\Sigma L| + \log |X^\top \Sigma^{-1}X|.\]</span>
Standard rules for determinants imply
<span class="math display">\[\log|L^\top\Sigma L| = \log|L^\top L\Sigma| = \log|L^\top L|+\log|\Sigma|.\]</span>
Using these simplified expressions, and noting that <span class="math inline">\(\log|L^\top L|\)</span> is constant in parameters, we may write the marginal (or residual) likelihood as
<span class="math display">\[\ell_r:= \text{const}.-\tfrac12 \log |\Sigma| +\tfrac12 \log|X^\top \Sigma^{-1} X| -\tfrac12 y^\top(\Sigma^{-1} - \Sigma^{-1}X(X^\top\Sigma^{-1} X)^{-1} X^\top\Sigma^{-1})y.\]</span></p>
<p>What is the reason for referring to <span class="math inline">\(\ell_r\)</span> as a <em>residual loglikelihood</em>? Recall <span class="math inline">\(\ell_r\)</span> is the marginal loglikelihood of <span class="math inline">\(L_2^\top Y\)</span> where <span class="math inline">\(L_2^\top X = 0\)</span>. Therefore,
<span class="math display">\[E(L_2^\top Y) = L_2^\top X\beta = (L_2^\top X)\beta = 0\beta = 0,\]</span>
which shows <span class="math inline">\(L_2^\top Y\)</span> behaves like a residual vector.</p>
<p>The REML estimate of <span class="math inline">\(\theta\)</span> is given by the maximizer of <span class="math inline">\(\ell_r\)</span> with respect to <span class="math inline">\(\theta\)</span>. Note also that this is simply the MLE of <span class="math inline">\(\theta\)</span> with respect to the marginal likelihood of <span class="math inline">\(L_2^\top Y\)</span>, i.e., the likelihood of “part of the data”.</p>
<p>Next, consider maximizing the conditional likelihood <span class="math inline">\(\ell_c\)</span> with respect to <span class="math inline">\(\beta\)</span> and where <span class="math inline">\(\theta=\hat\theta\)</span> is fixed at its REML estimate, i.e., <span class="math inline">\(\Sigma = \hat\Sigma\)</span>. Take the first derivative with respect to <span class="math inline">\(\beta\)</span>, equate to zero, and observe
<span class="math display">\[\begin{align*}
\hat\beta &amp;= y_1 - L_1^\top \Sigma L_2(L_2^\top \Sigma L_2)^{-1}y_2\\
&amp;= L_1^\top y - L_1^\top \Sigma L_2(L_2^\top \Sigma L_2)^{-1}L_2^\top y\\
&amp;= L_1^\top \Sigma \Sigma^{-1}y - L_1^\top \Sigma L_2(L_2^\top \Sigma L_2)^{-1}L_2^\top \Sigma\Sigma^{-1}y\\
&amp; = (L_1^\top \Sigma - (L_1^\top \Sigma L_2)(L_2^\top \Sigma L_2)^{-1}L_2^\top \Sigma)\Sigma^{-1}y\\
&amp; = (L_1^\top \Sigma L_1^\top X - (L_1^\top \Sigma L_2)(L_2^\top \Sigma L_2)^{-1}L_2^\top \Sigma L_1^\top X)\Sigma^{-1}y\\
&amp; = [(L_1^\top \Sigma L_1)-(L_1^\top \Sigma L_2)(L_2^\top \Sigma L_2)^{-1}(L_2^\top \Sigma L_1)]X\Sigma^{-1}y\\
&amp; = (X^\top \Sigma^{-1}X)^{-1}X^\top \Sigma^{-1}y,
\end{align*}\]</span>
using that <span class="math inline">\(L_1^\top X = I\)</span> and the equivalence between the conditional covariance of <span class="math inline">\(Y_1|y_2\)</span> and <span class="math inline">\((X^\top \Sigma^{-1}X)^{-1}\)</span> shown above.</p>
<p>We conclude that the REML estimator of <span class="math inline">\(\beta\)</span> is a weighted least squares estimator in which the weight matrix is given by the REML-based plug-in estimator <span class="math inline">\(\hat\Sigma^{-1}\)</span>.</p>
</div>
<div id="reml---bayesian-approach" class="section level3" number="4.2.2">
<h3>
<span class="header-section-number">4.2.2</span> REML - Bayesian approach<a class="anchor" aria-label="anchor" href="#reml---bayesian-approach"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose we model (in a Bayesian sense) the parameter <span class="math inline">\(\beta\)</span> with an improper constant prior, and the random component <span class="math inline">\(\alpha\)</span> with a multivariate normal prior with covariance <span class="math inline">\(\psi\)</span>. For whatever parameters define <span class="math inline">\(\theta\)</span>, endow those with constant/improper priors as well. Then, combining priors and multivariate normal likelihood we have the following posterior:
<span class="math display">\[\log\Pi_n(\beta) = \text{const.} - \tfrac12 \left(y - X\beta - Z\alpha\right)^\top \Lambda^{-1}\left(y - X\beta - Z\alpha\right) - \tfrac12\alpha^\top \psi^{-1}\alpha . \]</span>
A nice (but somewhat hard to find) factorization of the posterior is due to Searle et al. (Variance Components, Section 9.2). Expand the exponent:
<span class="math display">\[\begin{align*}
\log\Pi_n(\beta) &amp;= \text{const.} - \tfrac12 \left(y - X\beta\right)^\top \Lambda^{-1}\left(y - X\beta\right)\\
&amp;-\tfrac12 \alpha^\top (\psi^{-1} + Z^\top \Lambda^{-1}Z)\alpha + \alpha^\top Z^\top \Lambda^{-1}(y - X\beta)
\end{align*}\]</span>
Let <span class="math inline">\(A:=\psi^{-1} + Z^\top \Lambda^{-1}Z\)</span> and complete the square in <span class="math inline">\(\alpha\)</span>:
<span class="math display">\[\begin{align*}
\log\Pi_n(\beta) &amp;= \text{const.} - \tfrac12 \left(y - X\beta\right)^\top \Lambda^{-1}\left(y - X\beta\right)\\
&amp;-\tfrac12(\alpha - A^{-1}Z^\top\Lambda^{-1}(y-X\beta))^\top A(\alpha - A^{-1}Z^\top\Lambda^{-1}(y-X\beta))\\
&amp;+\tfrac12(y-X\beta)^\top\Lambda^{-1}ZA^{-1}Z^\top \Lambda^{-1} (y-X\beta).
\end{align*}\]</span>
Combine the terms quadratic in <span class="math inline">\(y-X\beta\)</span>. The resulting matrix <span class="math inline">\(\Lambda^{-1} - \Lambda^{-1}ZA^{-1}Z^\top \Lambda^{-1}\)</span> is equal to <span class="math inline">\((Z\psi Z^\top + \Lambda)^{-1}\)</span>, which is a fact we used above in the frequentist approach to REML. Therefore, the posterior factorizes into
<span class="math display" id="eq:preddist">\[\begin{equation}
\tag{4.6}
\begin{aligned}
\log\Pi_n(\beta) &amp;= \text{const.} - \tfrac12 \left(y - X\beta\right)^\top (Z\psi Z^\top +\Lambda)^{-1}(y - X\beta) \\
&amp;- \tfrac12(\alpha - A^{-1}Z^\top\Lambda^{-1}(y-X\beta))^\top A(\alpha - A^{-1}Z^\top\Lambda^{-1}(y-X\beta))
\end{aligned}
\end{equation}\]</span></p>
<p>Integrate over <span class="math inline">\(\alpha\)</span> to obtain the posterior for <span class="math inline">\(\beta\)</span>. Marginally, <span class="math inline">\(\alpha\)</span> is multivariate normal; therefore, we obtain
<span class="math display">\[\Pi_n(\beta) = (2\Pi)^{-n/2}|\Lambda|^{-1/2}|\psi|^{-1/2}|A|^{-1/2}\exp\left\{-\tfrac12 \left(y - X\beta\right)^\top (Z\psi Z^\top +\Lambda)^{-1}(y - X\beta)\right\}.\]</span></p>
<p>It can be verified that <span class="math inline">\(|Z\psi Z^\top +\Lambda| = |\Lambda||\psi||A|\)</span> by using the following identity
<span class="math display">\[|D^{-1} - CA^{-1}B| = |D||A^{-1}||A - BD^{-1}C|\]</span>
where <span class="math inline">\(Z\psi Z^\top +\Lambda = D^{-1} - CA^{-1}B = (\Lambda^{-1} - \Lambda^{-1}ZA^{-1}Z^\top \Lambda^{-1})^{-1}\)</span>; and, see, e.g., Appendix M equation 31 in Searle et al. (Variance Components). As a result, the posterior for <span class="math inline">\(\beta\)</span> is multivariate normal with covariance <span class="math inline">\(Z\psi Z^\top +\Lambda\)</span>.</p>
<p>In the exponent, add and subtract <span class="math inline">\(X\hat\beta = X(X^\top \Sigma^{-1} X)^{-1}X^\top \Sigma^{-1}y\)</span> (which depends on <span class="math inline">\(\theta\)</span>) in the quadratic to obtain
<span class="math display">\[\begin{align*}
\left(y - X\beta\right)^\top \Sigma^{-1}(y - X\beta) &amp; = \left(y - X\hat\beta\right)^\top \Sigma^{-1}(y - X\hat\beta)\\
&amp; -2 \left(y - X\hat\beta\right)^\top \Sigma^{-1}(X\hat\beta - X\beta)\\
&amp; + \left(X\hat\beta - X\beta\right)^\top \Sigma^{-1}(X\hat\beta - X\beta).
\end{align*}\]</span>
It is straightforward to show the middle term is zero. Therefore, the joint posterior for <span class="math inline">\((\beta, \theta)\)</span> may be written
<span class="math display">\[\log \Pi_n(\beta, \theta) = \text{const}. -\tfrac12\log|\Sigma|-\tfrac12(y-X\hat\beta)^\top \Sigma^{-1}(y-X\hat\beta) -\tfrac12(X\hat\beta - X\beta)\Sigma^{-1}(X\hat\beta - X\beta)\]</span></p>
<p>If we integrate out <span class="math inline">\(\beta\)</span> (w.r.t. a multivariate normal density), then we obtain the following marginal posterior for the variance parameters:
<span class="math display">\[\log\Pi_n(\theta) = \text{const.} - \tfrac{1}{2}\log|\Sigma| + \tfrac{1}{2}\log|X^\top \Sigma^{-1}X|-\tfrac12 \left(y - X\hat\beta\right)^\top \Sigma^{-1}(y - X\hat\beta).\]</span></p>
</div>
<div id="predicting-random-effects-and-responses" class="section level3" number="4.2.3">
<h3>
<span class="header-section-number">4.2.3</span> Predicting random effects and responses<a class="anchor" aria-label="anchor" href="#predicting-random-effects-and-responses"><i class="fas fa-link"></i></a>
</h3>
<p>If we set <span class="math inline">\(\beta = \hat\beta\)</span> in <a href="linear-mixed-models.html#eq:preddist">(4.6)</a> we see that the distribution of <span class="math inline">\(\alpha|\beta = \hat\beta\)</span> is multivariate normal with mean (and mode) equal to <span class="math inline">\(A^{-1}Z^\top\Lambda^{-1}(y-X\hat\beta)\)</span>. This quantity is the predictor <span class="math inline">\(\hat\alpha\)</span> of <span class="math inline">\(\alpha\)</span> when <span class="math inline">\(\beta\)</span> is set to the REML estimator, and it has a clear Bayesian interpretation as a posterior mean and maximum a posteriori point estimate.</p>
<p>The <em>best linear unbiased predictors</em> of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(Y\)</span> are equal to <span class="math inline">\(\hat\alpha\)</span> and <span class="math inline">\(X\hat\beta + Z\hat\alpha\)</span>.</p>
</div>
<div id="example-fitting-a-linear-mixed-model-to-loblolly-pines-data" class="section level3" number="4.2.4">
<h3>
<span class="header-section-number">4.2.4</span> Example: Fitting a linear mixed model to Loblolly pines data<a class="anchor" aria-label="anchor" href="#example-fitting-a-linear-mixed-model-to-loblolly-pines-data"><i class="fas fa-link"></i></a>
</h3>
<p>The data set “Loblolly” included in the nlme package contains longitudinal measurements of tree height for 14 Loblolly pine trees at 6 age points.</p>
<p>A plot of age by height for all trees suggests a common concave polynomial behavior—not quite linear.</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://svn.r-project.org/R-packages/trunk/nlme/">nlme</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span></code></pre></div>
<pre><code>## Warning: package 'ggplot2' was built under R version 4.1.3</code></pre>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Grouped Data: height ~ age | Seed
##    height age Seed
## 1    4.51   3  301
## 15  10.89   5  301
## 29  28.72  10  301
## 43  41.74  15  301
## 57  52.70  20  301
## 71  60.92  25  301</code></pre>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">Loblolly</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">Seed</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="GLMM_files/figure-html/unnamed-chunk-8-1.png" width="672"></div>
<p>To model the mean height behavior we might choose a, say, third degree polynomial function of age. There are a few ways of doing this: specify a polynomial in age, a polynomial in {age - mean(age)}, or a basis of orthogonal polynomials. Both the second and third strategies are better than the first as coefficients of polynomial elements tend to be highly correlated unless those polynomial elements are orthogonal or the variable is centered.</p>
<p>We could model height as polynomial in age using only fixed effects. However, if we want to account for variation in those polynomials over trees we can introduce tree-specific effects. Those tree-specific effects could be fixed or random, and the choice depends on the sampling mechanism used to collect the data. If those specific trees are of interest and were sampled intentionally then fixed tree effects are appropriate. On the other hand, if the observed trees represent a random sample from a population of trees, then random tree effects are appropriate. It is also worth pointing out that, in most cases, many more degrees of freedom would be needed to estimate tree-specific fixed effects compared to tree-specific random effects. This polynomial mixed effects model looks like the following
<span class="math display">\[\begin{align*}
Y_{ij} &amp;= \beta_0 + \beta_1 X_{ij1}+ \beta_2 X_{ij2}+ \beta_3 X_{ij3}\\
       &amp;+ \beta_{i1} X_{ij1}+ \beta_{i2} X_{ij2}+ \beta_{i3} X_{ij3}\\
       &amp; + \epsilon_{ij}
\end{align*}\]</span>
where <span class="math inline">\(i=1, \ldots, 14\)</span> indexes trees, <span class="math inline">\(j = 1, \ldots, 6\)</span> indexes ages, <span class="math inline">\(\beta_1\)</span> through <span class="math inline">\(\beta_3\)</span> are common coefficients for fixed polynomial age effects, and <span class="math inline">\(\beta_{i1}\)</span> through <span class="math inline">\(\beta_{i3}\)</span> are varying coefficients for age effects for each tree. The covariates <span class="math inline">\(X_{ij1}\)</span> through <span class="math inline">\(X_{ij3}\)</span> represent third degree orthogonal polynomials; i.e., they are not simply age, age<span class="math inline">\(^2\)</span> and age<span class="math inline">\(^3\)</span>, more on those shortly. The random effects are normal with covariance <span class="math inline">\(\psi\)</span>, i.e., <span class="math inline">\((\beta_{i1},\beta_{i2},\beta_{i3})^\top \stackrel{iid}{\sim}N(0,\psi)\)</span>.</p>
<p>Since tree heights are recorded over time/ages it also makes sense to consider auto-correlated errors <span class="math inline">\(\epsilon_{i,j}\)</span> with non-zero correlation over <span class="math inline">\(j\)</span> within <span class="math inline">\(i\)</span>. For now, modeling these errors as zero-mean, time-dependent normal random variables with non-zero auto-correlation at lag 1, meaning <span class="math inline">\((\epsilon_{i,j}, \epsilon_{i,j+1})\)</span> have non-zero correlation, so that <span class="math inline">\((\epsilon_{i1},\ldots, \epsilon_{i6})\stackrel{iid}{\sim} N(0,\Lambda)\)</span> where <span class="math inline">\(\Lambda\)</span> is positive definite and tri-diagonal.</p>
<p>Below we specify this model using the lme function from the nlme package. With default optimization specifications lme fails to fit this model, but lme converges if we simply increase the maximum number of iterations and function evaluations via the lmeControl function.</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/lmeControl.html">lmeControl</a></span><span class="op">(</span>niterEM<span class="op">=</span><span class="fl">1000</span>,msMaxIter<span class="op">=</span><span class="fl">1000</span>,msMaxEval<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/lme.html">lme</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>,</span>
<span>random <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>Seed <span class="op">=</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>correlation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/corAR1.html">corAR1</a></span><span class="op">(</span>form <span class="op">=</span> <span class="op">~</span> <span class="va">age</span><span class="op">|</span><span class="va">Seed</span><span class="op">)</span>, control <span class="op">=</span> <span class="va">lmc</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##   Data: Loblolly 
##        AIC      BIC    logLik
##   242.2632 280.3756 -105.1316
## 
## Random effects:
##  Formula: ~poly(age, 3) | Seed
##  Structure: General positive-definite, Log-Cholesky parametrization
##               StdDev    Corr                
## (Intercept)   1.4302075 (Intr) p(,3)1 p(,3)2
## poly(age, 3)1 6.5811089  0.915              
## poly(age, 3)2 2.6961875 -0.812 -0.509       
## poly(age, 3)3 0.5943500 -0.125 -0.514 -0.477
## Residual      0.5906168                     
## 
## Correlation Structure: ARMA(1,0)
##  Formula: ~age | Seed 
##  Parameter estimate(s):
##          Phi1 
## -2.944641e-07 
## Fixed effects:  height ~ poly(age, 3) 
##                   Value Std.Error DF   t-value p-value
## (Intercept)    32.36440 0.3876331 67  83.49237   0.000
## poly(age, 3)1 186.44570 1.8553896 67 100.48870   0.000
## poly(age, 3)2 -21.84656 0.9317043 67 -23.44796   0.000
## poly(age, 3)3   0.05782 0.6116048 67   0.09454   0.925
##  Correlation: 
##               (Intr) p(,3)1 p(,3)2
## poly(age, 3)1  0.856              
## poly(age, 3)2 -0.619 -0.373       
## poly(age, 3)3 -0.032 -0.126 -0.096
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.84043424 -0.43798962 -0.03581482  0.69326329  1.56774981 
## 
## Number of Observations: 84
## Number of Groups: 14</code></pre>
<p>While the summary function contains everything needed to determine if fixed effects are significant, it does not provide a straightforward explanation of all parameter estimates. With a little work, we can reproduce the estimated covariance parameters, and the estimated covariance of fixed effects. The getVarCov function provides the estimated covariance of the random effects nested within Seed; we could call these <span class="math inline">\(\hat\psi_i\)</span> for seeds <span class="math inline">\(i=1, \ldots, 14\)</span>. The matrix <span class="math inline">\(\psi\)</span> is block-diagonal, with identical blocks <span class="math inline">\(\psi_i\)</span>. The estimated residual variance is tri-diagonal with constant main diagonal elements <span class="math inline">\(\hat\sigma^2\)</span> given by <code>summary(model1)$sigma^2</code> and constant off-diagonal elements given by <code>coef(model1$modelStruct$corStruct, unconstrained = FALSE)</code>.</p>
<p>The following helper function from the Matrix package can help in constructing the <span class="math inline">\(\Psi\)</span> matrix:</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bdiag_m</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">lmat</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co">## Copyright (C) 2016 Martin Maechler, ETH Zurich</span></span>
<span>    <span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">lmat</span><span class="op">)</span><span class="op">)</span> <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu">new</span><span class="op">(</span><span class="st">"dgCMatrix"</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">is.list</a></span><span class="op">(</span><span class="va">lmat</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">is.matrix</a></span><span class="op">(</span><span class="va">lmat</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>,</span>
<span>              <span class="op">(</span><span class="va">k</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">lmat</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">==</span> <span class="va">d</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="co"># k x k</span></span>
<span>              <span class="fu"><a href="https://rdrr.io/r/base/all.html">all</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">vapply</a></span><span class="op">(</span><span class="va">lmat</span>, <span class="va">dim</span>, <span class="fu"><a href="https://rdrr.io/r/base/integer.html">integer</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">==</span> <span class="va">k</span><span class="op">)</span><span class="op">)</span> <span class="co"># all of them</span></span>
<span>    <span class="va">N</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">lmat</span><span class="op">)</span></span>
<span>    <span class="kw">if</span><span class="op">(</span><span class="va">N</span> <span class="op">*</span> <span class="va">k</span> <span class="op">&gt;</span> <span class="va">.Machine</span><span class="op">$</span><span class="va">integer.max</span><span class="op">)</span></span>
<span>        <span class="kw"><a href="https://rdrr.io/r/base/stop.html">stop</a></span><span class="op">(</span><span class="st">"resulting matrix too large; would be  M x M, with M="</span>, <span class="va">N</span><span class="op">*</span><span class="va">k</span><span class="op">)</span></span>
<span>    <span class="va">M</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">N</span> <span class="op">*</span> <span class="va">k</span><span class="op">)</span></span>
<span>    <span class="co">## result: an   M x M  matrix</span></span>
<span>    <span class="fu">new</span><span class="op">(</span><span class="st">"dgCMatrix"</span>, Dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">M</span>,<span class="va">M</span><span class="op">)</span>,</span>
<span>        <span class="co">## 'i :' maybe there's a faster way (w/o matrix indexing), but elegant?</span></span>
<span>        i <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fl">0L</span><span class="op">:</span><span class="op">(</span><span class="va">M</span><span class="op">-</span><span class="fl">1L</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">k</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>, each<span class="op">=</span><span class="va">k</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>,</span>
<span>        p <span class="op">=</span> <span class="va">k</span> <span class="op">*</span> <span class="fl">0L</span><span class="op">:</span><span class="va">M</span>,</span>
<span>        x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">lmat</span>, recursive<span class="op">=</span><span class="cn">FALSE</span>, use.names<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>We can match the standard errors and approximate p-values of the fixed effects using the following calculations (more on p-values later). One thing to mention: the <span class="math inline">\(Z\)</span> design matrix of random effects seems not present in the lme object, and so we fit the same type of model using lmer from the lme4 package that more easily allows us to obtain this model matrix. We could have constructed this “by hand” but it has a large, block structure, and it’s just easier to extract from built-in functions.</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span></span></code></pre></div>
<pre><code>## Warning: package 'lme4' was built under R version 4.1.3</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Warning: package 'Matrix' was built under R version 4.1.3</code></pre>
<pre><code>## 
## Attaching package: 'lme4'</code></pre>
<pre><code>## The following object is masked from 'package:nlme':
## 
##     lmList</code></pre>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model2lmer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span> <span class="op">|</span> <span class="va">Seed</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>, control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">lmerControl</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"Nelder_Mead"</span>, optCtrl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>maxfun <span class="op">=</span> <span class="fl">100000</span><span class="op">)</span>, check.conv.grad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">.makeCC</a></span><span class="op">(</span><span class="st">"warning"</span>, tol <span class="op">=</span> <span class="fl">0.71</span>, relTol <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">model2lmer</span>, type <span class="op">=</span> <span class="st">'random'</span><span class="op">)</span></span>
<span><span class="va">psi_i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/getVarCov.html">getVarCov</a></span><span class="op">(</span><span class="va">model1</span><span class="op">)</span></span>
<span><span class="va">psi</span> <span class="op">&lt;-</span> <span class="fu">bdiag_m</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">inv_psi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">psi</span><span class="op">)</span></span>
<span><span class="va">phi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">model1</span><span class="op">$</span><span class="va">modelStruct</span><span class="op">$</span><span class="va">corStruct</span>, unconstrained <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">L</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model1</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">L</span><span class="op">)</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">L</span><span class="op">)</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="kw">if</span><span class="op">(</span><span class="va">j</span><span class="op">==</span><span class="op">(</span><span class="va">i</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">||</span><span class="va">j</span><span class="op">==</span><span class="op">(</span><span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">{</span></span>
<span>      <span class="va">L</span><span class="op">[</span><span class="va">i</span>,<span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">phi</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span>
<span><span class="va">invL</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">L</span><span class="op">)</span></span>
<span><span class="va">A</span> <span class="op">&lt;-</span> <span class="va">inv_psi</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Z</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">invL</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">Z</span></span>
<span><span class="va">invA</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">A</span><span class="op">)</span></span>
<span><span class="va">P</span><span class="op">&lt;-</span><span class="va">invL</span><span class="op">-</span><span class="va">invL</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">Z</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">invA</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Z</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">invL</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">model2lmer</span>, type <span class="op">=</span> <span class="st">'fixed'</span><span class="op">)</span></span>
<span><span class="va">cov.beta.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">P</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">X</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">Loblolly</span><span class="op">$</span><span class="va">height</span></span>
<span><span class="va">beta.hat</span> <span class="op">&lt;-</span> <span class="va">cov.beta.hat</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">P</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">Y</span></span>
<span><span class="va">beta.hat</span></span></code></pre></div>
<pre><code>## 4 x 1 Matrix of class "dgeMatrix"
##              [,1]
## [1,]  32.36440477
## [2,] 186.44569514
## [3,] -21.84656380
## [4,]   0.05781863</code></pre>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cov.beta.hat</span></span></code></pre></div>
<pre><code>## 4 x 4 Matrix of class "dgeMatrix"
##              [,1]       [,2]        [,3]         [,4]
## [1,]  0.150259390  0.6154960 -0.22367703 -0.007593674
## [2,]  0.615495986  3.4424706 -0.64470993 -0.143514475
## [3,] -0.223677034 -0.6447099  0.86807296 -0.054643528
## [4,] -0.007593673 -0.1435145 -0.05464352  0.374060450</code></pre>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">beta.hat</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">cov.beta.hat</span><span class="op">)</span><span class="op">)</span> <span class="co"># t-values</span></span></code></pre></div>
<pre><code>## 4 x 1 Matrix of class "dgeMatrix"
##              [,1]
## [1,]  83.49237468
## [2,] 100.48870309
## [3,] -23.44795779
## [4,]   0.09453594</code></pre>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="op">(</span><span class="va">beta.hat</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">cov.beta.hat</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">1</span><span class="op">)</span> <span class="co"># rough p-values</span></span></code></pre></div>
<pre><code>## [1] 0.0000000 0.0000000 0.0000000 0.9246834</code></pre>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">pf</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="op">(</span><span class="va">beta.hat</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">cov.beta.hat</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">)</span><span class="op">-</span><span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.0000000 0.0000000 0.0000000 0.9249198</code></pre>
<p>You may have noticed the estimated auto-regressive covariance term is essentially zero. This motivates us to fit a nested model in which this covariance term is zero, i.e., the residual covariance structure of <span class="math inline">\(\epsilon_i\)</span>, <span class="math inline">\(i=1, \ldots, n\)</span> is simply iid with variance <span class="math inline">\(\sigma^2\)</span>.</p>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/lme.html">lme</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>,</span>
<span>random <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>Seed <span class="op">=</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>correlation <span class="op">=</span> <span class="cn">NULL</span>, control <span class="op">=</span> <span class="va">lmc</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by REML
##   Data: Loblolly 
##        AIC      BIC    logLik
##   240.2632 275.9936 -105.1316
## 
## Random effects:
##  Formula: ~poly(age, 3) | Seed
##  Structure: General positive-definite, Log-Cholesky parametrization
##               StdDev    Corr                
## (Intercept)   1.4301995 (Intr) p(,3)1 p(,3)2
## poly(age, 3)1 6.5810089  0.915              
## poly(age, 3)2 2.6961948 -0.812 -0.509       
## poly(age, 3)3 0.5943572 -0.125 -0.514 -0.477
## Residual      0.5906184                     
## 
## Fixed effects:  height ~ poly(age, 3) 
##                   Value Std.Error DF   t-value p-value
## (Intercept)    32.36440 0.3876310 67  83.49282   0.000
## poly(age, 3)1 186.44570 1.8553648 67 100.49005   0.000
## poly(age, 3)2 -21.84656 0.9317069 67 -23.44789   0.000
## poly(age, 3)3   0.05782 0.6116069 67   0.09454   0.925
##  Correlation: 
##               (Intr) p(,3)1 p(,3)2
## poly(age, 3)1  0.856              
## poly(age, 3)2 -0.619 -0.373       
## poly(age, 3)3 -0.032 -0.126 -0.096
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.84042613 -0.43799912 -0.03581492  0.69325898  1.56775714 
## 
## Number of Observations: 84
## Number of Groups: 14</code></pre>
<p>NLME is not the only package for fitting linear mixed models. LME4 is a newer package compared to NLME, and generally fits models much faster thanks to its better use of efficient linear algebra routines. However, LME4 is not as flexible as NLME when it comes to the available residual covariance structures one is able to fit. For example, LME4 does not have the flexibility to fit the AR(1) structure we fit for model1 above using the NLME package.</p>
<p>Below we fit model2 using LME4. The lmer model fitting function fails to fit the model with the default settings, much like the lme function from the NLME package. The main issue causing lack of convergence is a check function that evaluates the gradient of the likelihood at the final parameter estimates and requires it to be near zero. We have to violate this criteria in order to get the model to fit, which we can do by using the <code>check.conv.grad</code> argument of the control argument. Once we coerce lmer to converge using these options we see that it produces essentially the same estimates as lme with respect to model2.</p>
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span></span>
<span><span class="va">model2lmer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span> <span class="op">|</span> <span class="va">Seed</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>, control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">lmerControl</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"Nelder_Mead"</span>, optCtrl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>maxfun <span class="op">=</span> <span class="fl">100000</span><span class="op">)</span>, check.conv.grad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">.makeCC</a></span><span class="op">(</span><span class="st">"warning"</span>, tol <span class="op">=</span> <span class="fl">0.71</span>, relTol <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model2lmer</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Linear mixed model fit by REML ['lmerMod']
## Formula: height ~ poly(age, 3) + (poly(age, 3) | Seed)
##    Data: Loblolly
## Control: 
## lmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 1e+05),  
##     check.conv.grad = .makeCC("warning", tol = 0.71, relTol = NULL))
## 
## REML criterion at convergence: 210.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.83857 -0.45408 -0.02587  0.65608  1.54812 
## 
## Random effects:
##  Groups   Name          Variance Std.Dev. Corr             
##  Seed     (Intercept)    1.9497  1.3963                    
##           poly(age, 3)1 40.8246  6.3894    0.91            
##           poly(age, 3)2  7.2430  2.6913   -0.82 -0.50      
##           poly(age, 3)3  0.6555  0.8096   -0.03 -0.37 -0.44
##  Residual                0.3506  0.5922                    
## Number of obs: 84, groups:  Seed, 14
## 
## Fixed effects:
##                Estimate Std. Error t value
## (Intercept)    32.36440    0.37873  85.455
## poly(age, 3)1 186.44570    1.80740 103.157
## poly(age, 3)2 -21.84656    0.93167 -23.449
## poly(age, 3)3   0.05782    0.63045   0.092
## 
## Correlation of Fixed Effects:
##             (Intr) p(,3)1 p(,3)2
## poly(ag,3)1  0.846              
## poly(ag,3)2 -0.621 -0.367       
## poly(ag,3)3 -0.011 -0.119 -0.117</code></pre>
<p>Next, we will investigate various residual quantities to determine if our model assumptions are plausible.</p>
</div>
</div>
<div id="model-diagnostics" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Model diagnostics<a class="anchor" aria-label="anchor" href="#model-diagnostics"><i class="fas fa-link"></i></a>
</h2>
<p>As in pure fixed effects linear models, residuals are helpful for checking assumptions like linearity and normality. For mixed effects models, there are more ways to define residuals:</p>
<ul>
<li><p>Marginal residuals are the residuals formed by subtracting the fitted fixed effect from the response, that is, <span class="math inline">\(\hat e_{ij} := Y_{ij} - x_{ij}^\top \hat\beta\)</span></p></li>
<li><p>Standardized marginal residuals remove the effect of correlation. The estimated covariance of <span class="math inline">\(\hat e\)</span> is <span class="math inline">\(\hat\Sigma(\hat e) := \hat\Sigma - X(X^\top \hat\Sigma^{-1} X)^{-1}X^\top\)</span>. Let <span class="math inline">\(\hat\Sigma_i(\hat e)\)</span> denote the fitted covariance of marginal residuals within group <span class="math inline">\(i\)</span>, and let <span class="math inline">\(\hat\Sigma_i(\hat e)^{-1/2}\)</span> denote the lower Cholesky factor of <span class="math inline">\(\hat\Sigma_i(\hat e)^{-1}\)</span>. Then, <span class="math inline">\(\hat \epsilon_{i} = \hat\Sigma_i(\hat e)^{-1/2}\hat e_i\)</span> denotes the vector of standardized marginal residuals for group <span class="math inline">\(i\)</span>.</p></li>
<li><p>Conditional residuals also subtract the predicted random effect, <span class="math inline">\(\hat \xi_{ij} = Y_{ij} - x_{ij}^\top \hat\beta - z_{ij}^\top \hat \alpha\)</span></p></li>
<li><p>Standardized conditional residuals <span class="math inline">\(\hat\phi_{ij}\)</span> are formed by standardizing the conditional residuals by their estimated covariance, just as in the case of marginal residuals. The estimated covariance of conditional residuals is given by
<span class="math display">\[\hat\Sigma(\hat \phi) := (I-Z\hat A^{-1}Z^\top \hat\Lambda^{-1})\hat\Sigma(\hat e)(I-\hat\Lambda^{-1}Z\hat A^{-1}Z^\top).\]</span></p></li>
</ul>
<p>A scatterplot of marginal residuals versus fixed covariates is useful for checking the assumption of linearity. Trends in this plot indicate an important omitted variable and/or nonlinearity.</p>
<p>Quantile-quantile plots of standardized marginal residuals within groups should match a standard normal distribution. If not, then the chosen within-group covariance structure is not good model for the given data. Comparing quantile-quantile plots for each group can be useful for assessing heteroskedasticity, although these comparisons become rough when groups have few individuals.</p>
<p>Large absolute standardized conditional residuals are indicate outliers. Plots of standardized conditional residuals versus the fitted values <span class="math inline">\(X\hat\beta + Z\hat\alpha\)</span> may also reveal heteroskedasticity over/between groups—which would suggest modifying the structure of <span class="math inline">\(\Lambda\)</span> if it is assumed to be <span class="math inline">\(\sigma^2 I_n\)</span> as is common.</p>
<div id="model-diagnostics-for-loblolly-pines-data" class="section level3" number="4.3.1">
<h3>
<span class="header-section-number">4.3.1</span> Model diagnostics for Loblolly pines data<a class="anchor" aria-label="anchor" href="#model-diagnostics-for-loblolly-pines-data"><i class="fas fa-link"></i></a>
</h3>
<p>We begin by plotting the amrginal residuals from the cubic model fit with LME4 which we called model2. The marginal residuals exhibit some pattern in age. This suggests fitting a higher-order polynomial model.</p>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">marginal.resids</span> <span class="op">&lt;-</span> <span class="va">Loblolly</span><span class="op">$</span><span class="va">height</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">model2lmer</span>, type <span class="op">=</span> <span class="st">'fixed'</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">model2lmer</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">$</span><span class="va">age</span>, <span class="va">marginal.resids</span>, xlab <span class="op">=</span> <span class="st">'age'</span>, ylab <span class="op">=</span> <span class="st">'marginal residual'</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="GLMM_files/figure-html/unnamed-chunk-14-1.png" width="672"></div>
<p>A 5th order polynomial appears to fit the data; however, we cannot include 5th order polynomial random effects, so we will need to make some choice on random effect structure by investigating standardized residuals.</p>
<div class="sourceCode" id="cb95"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span></span>
<span><span class="va">model3lmer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">5</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Seed</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>, control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">lmerControl</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"Nelder_Mead"</span>, optCtrl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>maxfun <span class="op">=</span> <span class="fl">100000</span><span class="op">)</span>, check.conv.grad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">.makeCC</a></span><span class="op">(</span><span class="st">"warning"</span>, tol <span class="op">=</span> <span class="fl">0.71</span>, relTol <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">marginal.resids3</span> <span class="op">&lt;-</span> <span class="va">Loblolly</span><span class="op">$</span><span class="va">height</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">model3lmer</span>, type <span class="op">=</span> <span class="st">'fixed'</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">model3lmer</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">$</span><span class="va">age</span>, <span class="va">marginal.resids3</span>, xlab <span class="op">=</span> <span class="st">'age'</span>, ylab <span class="op">=</span> <span class="st">'marginal residual'</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="GLMM_files/figure-html/unnamed-chunk-15-1.png" width="672"></div>
<p>Above we fit a 5th-order polynomial model with only random intercepts by Seed/tree. This means that each tree’s age-height relationship is simply a shifted (up or down) version of the same polynomial. Based on our BLUPs, plotted below, the random effects do not seem sufficiently flexible to model trees 329, 327, and 305, for example. It certainly looks like we need to add random polynomial effects.</p>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Loblolly</span><span class="op">$</span><span class="va">fitted3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">model3lmer</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">Loblolly</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">fitted3</span>, color <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">Seed</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="GLMM_files/figure-html/unnamed-chunk-16-1.png" width="672"></div>
<p>Taking those poorly-fitting BLUPs into account, we fit a model with quadratic random effects. Our predictions look much more accurate after including these additional random effects.</p>
<div class="sourceCode" id="cb97"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model4lmer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">5</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">2</span><span class="op">)</span> <span class="op">|</span> <span class="va">Seed</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>, control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">lmerControl</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"Nelder_Mead"</span>, optCtrl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>maxfun <span class="op">=</span> <span class="fl">100000</span><span class="op">)</span>, check.conv.grad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">.makeCC</a></span><span class="op">(</span><span class="st">"warning"</span>, tol <span class="op">=</span> <span class="fl">0.71</span>, relTol <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## boundary (singular) fit: see help('isSingular')</code></pre>
<div class="sourceCode" id="cb99"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">marginal.resids4</span> <span class="op">&lt;-</span> <span class="va">Loblolly</span><span class="op">$</span><span class="va">height</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">model4lmer</span>, type <span class="op">=</span> <span class="st">'fixed'</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">model4lmer</span><span class="op">)</span></span>
<span><span class="va">Loblolly</span><span class="op">$</span><span class="va">fitted4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">model4lmer</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">Loblolly</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">fitted4</span>, color <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">Seed</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="GLMM_files/figure-html/unnamed-chunk-17-1.png" width="672"></div>
<p>The following calculations produce standardized marginal residuals, which we can investigate for normality and the overall appropriateness of the within tree covariance structure.</p>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">model4lmer</span>, type <span class="op">=</span> <span class="st">'random'</span><span class="op">)</span></span>
<span><span class="va">dim_cov</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/VarCorr.html">VarCorr</a></span><span class="op">(</span><span class="va">model4lmer</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">$</span><span class="va">Seed</span>, <span class="st">'correlation'</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">psi_i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/VarCorr.html">VarCorr</a></span><span class="op">(</span><span class="va">model4lmer</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">$</span><span class="va">Seed</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">dim_cov</span>,<span class="fl">1</span><span class="op">:</span><span class="va">dim_cov</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">psi</span> <span class="op">&lt;-</span> <span class="fu">bdiag_m</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span>,<span class="va">psi_i</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">inv_psi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">psi</span><span class="op">)</span></span>
<span><span class="va">phi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">model1</span><span class="op">$</span><span class="va">modelStruct</span><span class="op">$</span><span class="va">corStruct</span>, unconstrained <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">L</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model4lmer</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">invL</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">L</span><span class="op">)</span></span>
<span><span class="va">A</span> <span class="op">&lt;-</span> <span class="va">inv_psi</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Z</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">invL</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">Z</span></span>
<span><span class="va">invA</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">A</span><span class="op">)</span></span>
<span><span class="va">P</span><span class="op">&lt;-</span><span class="va">invL</span><span class="op">-</span><span class="va">invL</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">Z</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">invA</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Z</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">invL</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">model4lmer</span>, type <span class="op">=</span> <span class="st">'fixed'</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cov.beta.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">P</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">X</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">Loblolly</span><span class="op">$</span><span class="va">height</span></span>
<span><span class="va">beta.hat</span> <span class="op">&lt;-</span> <span class="va">cov.beta.hat</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">P</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">Y</span></span>
<span><span class="va">Pi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">P</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span></span>
<span><span class="va">cholPi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/chol.html">chol</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">Pi</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">standardized_resids</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>,<span class="fl">84</span><span class="op">)</span></span>
<span><span class="va">seed</span><span class="op">=</span><span class="fl">1</span></span>
<span><span class="va">cov.check</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">14</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">standardized_resids</span><span class="op">[</span><span class="op">(</span><span class="va">seed</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fl">6</span><span class="op">+</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">cholPi</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">marginal.resids4</span><span class="op">[</span><span class="op">(</span><span class="va">seed</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fl">6</span><span class="op">+</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span><span class="op">]</span></span>
<span>  <span class="va">cov.check</span> <span class="op">&lt;-</span> <span class="va">cov.check</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="fl">6</span><span class="op">)</span><span class="op">-</span><span class="va">standardized_resids</span><span class="op">[</span><span class="op">(</span><span class="va">seed</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fl">6</span><span class="op">+</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span><span class="op">]</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">standardized_resids</span><span class="op">[</span><span class="op">(</span><span class="va">seed</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="fl">6</span><span class="op">+</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span>  <span class="va">seed</span> <span class="op">&lt;-</span> <span class="va">seed</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">Loblolly</span><span class="op">$</span><span class="va">standardized_resids</span> <span class="op">&lt;-</span> <span class="va">standardized_resids</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span></code></pre></div>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --</code></pre>
<pre><code>## v tibble  3.1.8      v dplyr   1.0.10
## v tidyr   1.2.1      v stringr 1.4.1 
## v readr   2.1.1      v forcats 0.5.1 
## v purrr   0.3.4</code></pre>
<pre><code>## Warning: package 'tibble' was built under R version 4.1.3</code></pre>
<pre><code>## Warning: package 'tidyr' was built under R version 4.1.3</code></pre>
<pre><code>## Warning: package 'dplyr' was built under R version 4.1.3</code></pre>
<pre><code>## Warning: package 'stringr' was built under R version 4.1.3</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::collapse() masks nlme::collapse()
## x tidyr::expand()   masks Matrix::expand()
## x dplyr::filter()   masks stats::filter()
## x dplyr::lag()      masks stats::lag()
## x tidyr::pack()     masks Matrix::pack()
## x tidyr::unpack()   masks Matrix::unpack()</code></pre>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Loblolly</span><span class="op">&lt;-</span><span class="va">Loblolly</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">Seed</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>sd_stan_resids <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">standardized_resids</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">sd_stan_resids</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">ungroup</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Loblolly</span><span class="op">$</span><span class="va">Seed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">$</span><span class="va">Seed</span>, ordered <span class="op">=</span> <span class="cn">FALSE</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">$</span><span class="va">Seed</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">$</span><span class="va">Seed</span>, <span class="va">Loblolly</span><span class="op">$</span><span class="va">standardized_resids</span>, xlab <span class="op">=</span> <span class="st">'Seed'</span>, ylab <span class="op">=</span> <span class="st">'standardized marginal residual'</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">6</span>,<span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="GLMM_files/figure-html/unnamed-chunk-18-1.png" width="672"></div>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fakedata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">84</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">4</span>,<span class="fl">6</span><span class="op">)</span>,</span>
<span>                                <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">5</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">6</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">7</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">8</span>,<span class="fl">6</span><span class="op">)</span>,</span>
<span>                                <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">9</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">11</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">12</span>,<span class="fl">6</span><span class="op">)</span>,</span>
<span>                                <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">13</span>,<span class="fl">6</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">14</span>,<span class="fl">6</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fakedata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">fakedata</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fakedata</span><span class="op">&lt;-</span><span class="va">fakedata</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">X2</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>sd_X1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">X1</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">sd_X1</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">ungroup</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fakedata</span><span class="op">$</span><span class="va">X2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">fakedata</span><span class="op">$</span><span class="va">X2</span>, ordered <span class="op">=</span> <span class="cn">FALSE</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">fakedata</span><span class="op">$</span><span class="va">X2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fakedata</span><span class="op">$</span><span class="va">X2</span>, <span class="va">fakedata</span><span class="op">$</span><span class="va">X1</span>, xlab <span class="op">=</span> <span class="st">'random normals'</span>, ylab <span class="op">=</span> <span class="st">'sample standard deviation'</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">6</span>,<span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="GLMM_files/figure-html/unnamed-chunk-18-2.png" width="672"></div>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">B</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="va">Z</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">invA</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Z</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="va">invL</span><span class="op">)</span></span>
<span><span class="va">P2</span> <span class="op">&lt;-</span> <span class="va">B</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">P</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">B</span><span class="op">)</span></span>
<span><span class="va">cholP2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/chol.html">chol</a></span><span class="op">(</span><span class="va">P2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">standardized_conditional_residuals</span> <span class="op">&lt;-</span> <span class="va">cholP2</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">-</span> <span class="va">Loblolly</span><span class="op">$</span><span class="va">fitted4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">standardized_conditional_residuals</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqline</a></span><span class="op">(</span><span class="va">standardized_conditional_residuals</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="GLMM_files/figure-html/unnamed-chunk-18-3.png" width="672"></div>
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">standardized_conditional_residuals</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  as.numeric(standardized_conditional_residuals)
## W = 0.68254, p-value = 3.481e-12</code></pre>
<p>Next, we will discuss inference for fixed effects and model comparisons.</p>
</div>
</div>
<div id="inference-for-fixed-effects-random-effects-and-model-comparisons" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> Inference for fixed effects, random effects, and model comparisons<a class="anchor" aria-label="anchor" href="#inference-for-fixed-effects-random-effects-and-model-comparisons"><i class="fas fa-link"></i></a>
</h2>
<p>The most common inferential questions concern the regression coefficient vector <span class="math inline">\(\beta\)</span>. Wald confidence regions for <span class="math inline">\(\beta\)</span> are defined by the sets
<span class="math display">\[C_\alpha := \{b: (b - \hat\beta)(X^\top V^{-1}X)^{-1}(b - \hat\beta)&lt;\chi^2_{1-\alpha, p}\}\]</span>
where <span class="math inline">\(\chi^2_{1-\alpha, p}\)</span> is the upper <span class="math inline">\(\alpha\)</span> quantile of the Chi-squared distribution with <span class="math inline">\(p\)</span> degrees of freedom. Unfortunately, these regions are only exact when <span class="math inline">\(\theta\)</span> is known and can severely undercover for small sample sizes. Software packages typically perform an adjustment, such as the Kenward-Rogers scaling, which is a generalization of Satterthwaite’s approximation.</p>
<p>For a point null hypothesis <span class="math inline">\(H_0: \beta = \beta_{0}\)</span> the Wald test statistic is
<span class="math display">\[W = (\beta_0 - \hat\beta)(X^\top V^{-1}X)^{-1}(\beta_0 - \hat\beta)\]</span>
and <span class="math inline">\(H_0\)</span> is rejected if <span class="math inline">\(W &gt; \chi^2_{1-\alpha, p}\)</span>. More generally, let <span class="math inline">\(D\)</span> denote an <span class="math inline">\(r\times p\)</span> matrix <span class="math inline">\(r&lt;p\)</span> of full rank. Reject the null hypothesis <span class="math inline">\(H_0:D\beta = b_0\)</span> if <span class="math inline">\(W &gt; \chi^2_{1-\alpha, r}\)</span> where
<span class="math display">\[W = (b_0 - D\hat\beta)(D X^\top V^{-1}X D^\top)^{-1}(b_0 - D\hat\beta)\]</span></p>
<p>(Generalized) Likelihood ratio tests may be used to compare <em>nested</em> models. Model A is nested in B if A may be written as B with some of B’s parameters equal to zero, provided zero is not a boundary value for the parameter being omitted in model A. For example, A is nested in B if A contains only a subset of B’s fixed effects, a subset of B’s random effects, a nested residual covariance structure like iid versus AR(1) as in the above example, or a combination of these three. When likelihood ratio tests are performed to compare nested models with different fixed effects both models should be fit using maximum likelihood rather than REML because residual likelihoods for two different sets of fixed effects are not comparable.</p>
<p>An example of models that are not nested is the cubic model above called model1 versus a model with linear, quadratic and fourth order fixed effects but no third order fixed effect. AIC and/or BIC comparisons (based on the full likelihoods) are useful for comparing non-nested models (remember: lower AIC/BIC is better).</p>
<p>As mentioned previously, in the context of linear mixed models, test statistics rarely have exact Chi-squared or F null distributions—the exceptions pertain to balanced experiments. In fact, these approximations may be very rough, depending on the model and sample sizes. For this reason, the LMER package does not even report p-values at this time. But, there are a few options for producing fairly reliable p-values. One option is to utilize the lmerTest package which provides functions for testing fixed effects using Satterthwaite or Kenward-Rogers corrected null distributions. Another option is to use the parametric bootstrap (based on sampling a multivariate normal distribution) to provide bootstrap-based tests and confidence intervals. The bootstrap method is endorsed by the creators of LME4, and they have included the bootMer function in that package to facilitate bootstrap-based inference in linear mixed models.</p>
<div id="inference-on-fixed-effects-for-loblolly-pines-data" class="section level3" number="4.4.1">
<h3>
<span class="header-section-number">4.4.1</span> Inference on fixed effects for Loblolly pines data<a class="anchor" aria-label="anchor" href="#inference-on-fixed-effects-for-loblolly-pines-data"><i class="fas fa-link"></i></a>
</h3>
<p>The first question of interest, which we hinted at before, is whether or not we need to model the residual error as having a time-dependent, e.g., AR(1), structure. Recall our point estimate for the auto-regressive correlation was essentially zero, suggesting it played no role in the model fit. The NLME package contains an anova method for comparing models. While we should get into the habit of comparing models fit by maximum likelihood, it makes little difference if we use REML for this comparison because the models only differ in covariance structure, not fixed-effects structure. Whether we compare models fit by REML or ML, we see overwhelming evidence that the simpler model, the one without an auto-regressive error structure, is just as good as the more complicated model.</p>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model1</span>, <span class="va">model2</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        Model df      AIC      BIC    logLik   Test      L.Ratio p-value
## model1     1 16 242.2632 280.3756 -105.1316                            
## model2     2 15 240.2632 275.9936 -105.1316 1 vs 2 7.727313e-06  0.9978</code></pre>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model2ml</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/lme.html">lme</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>,</span>
<span>random <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>Seed <span class="op">=</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>correlation <span class="op">=</span> <span class="cn">NULL</span>, control <span class="op">=</span> <span class="va">lmc</span>, method <span class="op">=</span> <span class="st">'ML'</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model2ml</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: Loblolly 
##      AIC      BIC   logLik
##   243.71 280.1723 -106.855
## 
## Random effects:
##  Formula: ~poly(age, 3) | Seed
##  Structure: General positive-definite, Log-Cholesky parametrization
##               StdDev    Corr                
## (Intercept)   1.3775131 (Intr) p(,3)1 p(,3)2
## poly(age, 3)1 6.3314123  0.917              
## poly(age, 3)2 2.5866151 -0.815 -0.516       
## poly(age, 3)3 0.5669801 -0.127 -0.512 -0.471
## Residual      0.5799748                     
## 
## Fixed effects:  height ~ poly(age, 3) 
##                   Value Std.Error DF   t-value p-value
## (Intercept)    32.36440 0.3827797 67  84.55099  0.0000
## poly(age, 3)1 186.44570 1.8329479 67 101.71904  0.0000
## poly(age, 3)2 -21.84656 0.9246527 67 -23.62678  0.0000
## poly(age, 3)3   0.05782 0.6142470 67   0.09413  0.9253
##  Correlation: 
##               (Intr) p(,3)1 p(,3)2
## poly(age, 3)1  0.855              
## poly(age, 3)2 -0.615 -0.374       
## poly(age, 3)3 -0.032 -0.123 -0.091
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.88464265 -0.45304355 -0.03408912  0.70340863  1.60926117 
## 
## Number of Observations: 84
## Number of Groups: 14</code></pre>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model1ml</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/lme.html">lme</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>,</span>
<span>random <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>Seed <span class="op">=</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>correlation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/corAR1.html">corAR1</a></span><span class="op">(</span>form <span class="op">=</span> <span class="op">~</span> <span class="va">age</span><span class="op">|</span><span class="va">Seed</span><span class="op">)</span>, control <span class="op">=</span> <span class="va">lmc</span>, method <span class="op">=</span> <span class="st">'ML'</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model1ml</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Linear mixed-effects model fit by maximum likelihood
##   Data: Loblolly 
##      AIC      BIC   logLik
##   245.71 284.6031 -106.855
## 
## Random effects:
##  Formula: ~poly(age, 3) | Seed
##  Structure: General positive-definite, Log-Cholesky parametrization
##               StdDev    Corr                
## (Intercept)   1.3775271 (Intr) p(,3)1 p(,3)2
## poly(age, 3)1 6.3314017  0.917              
## poly(age, 3)2 2.5866169 -0.815 -0.516       
## poly(age, 3)3 0.5669567 -0.128 -0.512 -0.471
## Residual      0.5799733                     
## 
## Correlation Structure: ARMA(1,0)
##  Formula: ~age | Seed 
##  Parameter estimate(s):
##         Phi1 
## -3.18889e-08 
## Fixed effects:  height ~ poly(age, 3) 
##                   Value Std.Error DF   t-value p-value
## (Intercept)    32.36440 0.3827835 67  84.55016  0.0000
## poly(age, 3)1 186.44570 1.8329446 67 101.71922  0.0000
## poly(age, 3)2 -21.84656 0.9246521 67 -23.62679  0.0000
## poly(age, 3)3   0.05782 0.6142439 67   0.09413  0.9253
##  Correlation: 
##               (Intr) p(,3)1 p(,3)2
## poly(age, 3)1  0.855              
## poly(age, 3)2 -0.615 -0.374       
## poly(age, 3)3 -0.032 -0.123 -0.091
## 
## Standardized Within-Group Residuals:
##         Min          Q1         Med          Q3         Max 
## -1.88462925 -0.45305131 -0.03409201  0.70342933  1.60926556 
## 
## Number of Observations: 84
## Number of Groups: 14</code></pre>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model1ml</span>, <span class="va">model2ml</span><span class="op">)</span></span></code></pre></div>
<pre><code>##          Model df    AIC      BIC   logLik   Test      L.Ratio p-value
## model1ml     1 16 245.71 284.6031 -106.855                            
## model2ml     2 15 243.71 280.1723 -106.855 1 vs 2 1.314233e-06  0.9991</code></pre>
<p>Next we investigate whether we a cubic function or a simpler quadratic is enough to model the age-height relationship. Using lmerTest we can produce corrected p-values for each fixed effect within model2—the model with an iid residual error structure. It’s clear that the cubic term provides no benefit, so we omit it and fit model3. An anova method is also included with lmer, and notice that lmer automatically recognizes we want to compare nested models with differeing fixed effects and refits those models by ML—how delightful. Again, the simpler, quadratic model is clearly preferred.</p>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model2lmer</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Linear mixed model fit by REML ['lmerMod']
## Formula: height ~ poly(age, 3) + (poly(age, 3) | Seed)
##    Data: Loblolly
## Control: 
## lmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 1e+05),  
##     check.conv.grad = .makeCC("warning", tol = 0.71, relTol = NULL))
## 
## REML criterion at convergence: 210.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.83857 -0.45408 -0.02587  0.65608  1.54812 
## 
## Random effects:
##  Groups   Name          Variance Std.Dev. Corr             
##  Seed     (Intercept)    1.9497  1.3963                    
##           poly(age, 3)1 40.8246  6.3894    0.91            
##           poly(age, 3)2  7.2430  2.6913   -0.82 -0.50      
##           poly(age, 3)3  0.6555  0.8096   -0.03 -0.37 -0.44
##  Residual                0.3506  0.5922                    
## Number of obs: 84, groups:  Seed, 14
## 
## Fixed effects:
##                Estimate Std. Error t value
## (Intercept)    32.36440    0.37873  85.455
## poly(age, 3)1 186.44570    1.80740 103.157
## poly(age, 3)2 -21.84656    0.93167 -23.449
## poly(age, 3)3   0.05782    0.63045   0.092
## 
## Correlation of Fixed Effects:
##             (Intr) p(,3)1 p(,3)2
## poly(ag,3)1  0.846              
## poly(ag,3)2 -0.621 -0.367       
## poly(ag,3)3 -0.011 -0.119 -0.117</code></pre>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/runehaubo/lmerTestR">lmerTest</a></span><span class="op">)</span></span></code></pre></div>
<pre><code>## Warning: package 'lmerTest' was built under R version 4.1.3</code></pre>
<pre><code>## 
## Attaching package: 'lmerTest'</code></pre>
<pre><code>## The following object is masked from 'package:lme4':
## 
##     lmer</code></pre>
<pre><code>## The following object is masked from 'package:stats':
## 
##     step</code></pre>
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">Loblolly</span><span class="op">$</span><span class="va">age</span>,<span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">Loblolly</span><span class="op">$</span><span class="va">linear</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">Loblolly</span><span class="op">$</span><span class="va">quadratic</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">Loblolly</span><span class="op">$</span><span class="va">cubic</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span></span>
<span><span class="va">model2lmer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lmerTest/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">linear</span><span class="op">+</span><span class="va">quadratic</span><span class="op">+</span><span class="va">cubic</span> <span class="op">+</span> <span class="op">(</span><span class="va">linear</span><span class="op">+</span><span class="va">quadratic</span><span class="op">+</span><span class="va">cubic</span> <span class="op">|</span> <span class="va">Seed</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span>, control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">lmerControl</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"Nelder_Mead"</span>, optCtrl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>maxfun <span class="op">=</span> <span class="fl">100000</span><span class="op">)</span>, check.conv.grad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">.makeCC</a></span><span class="op">(</span><span class="st">"warning"</span>, tol <span class="op">=</span> <span class="fl">0.71</span>, relTol <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model2lmer</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite's method [
## lmerModLmerTest]
## Formula: height ~ linear + quadratic + cubic + (linear + quadratic + cubic |  
##     Seed)
##    Data: Loblolly
## Control: 
## lmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun = 1e+05),  
##     check.conv.grad = .makeCC("warning", tol = 0.71, relTol = NULL))
## 
## REML criterion at convergence: 210.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.83857 -0.45408 -0.02587  0.65608  1.54811 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr             
##  Seed     (Intercept)  1.9497  1.3963                    
##           linear      40.8247  6.3894    0.91            
##           quadratic    7.2430  2.6913   -0.82 -0.50      
##           cubic        0.6555  0.8096   -0.03 -0.37 -0.44
##  Residual              0.3506  0.5922                    
## Number of obs: 84, groups:  Seed, 14
## 
## Fixed effects:
##              Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept)  32.36440    0.37873  13.91872  85.455  &lt; 2e-16 ***
## linear      186.44570    1.80740  14.11654 103.157  &lt; 2e-16 ***
## quadratic   -21.84656    0.93167  14.62277 -23.449 5.21e-13 ***
## cubic         0.05782    0.63045  26.65569   0.092    0.928    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Correlation of Fixed Effects:
##           (Intr) linear qudrtc
## linear     0.846              
## quadratic -0.621 -0.367       
## cubic     -0.011 -0.119 -0.117</code></pre>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model2lmer</span>, type <span class="op">=</span> <span class="st">'III'</span>, ddf <span class="op">=</span> <span class="st">'lme4'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
##           npar Sum Sq Mean Sq    F value
## linear       1 3702.8  3702.8 10559.8644
## quadratic    1  195.3   195.3   556.9927
## cubic        1    0.0     0.0     0.0084</code></pre>
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model2lmer</span>, type <span class="op">=</span> <span class="st">'III'</span>, ddf <span class="op">=</span> <span class="st">'Satt'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Type III Analysis of Variance Table with Satterthwaite's method
##           Sum Sq Mean Sq NumDF  DenDF    F value    Pr(&gt;F)    
## linear    3731.4  3731.4     1 14.117 10641.3242 &lt; 2.2e-16 ***
## quadratic  192.8   192.8     1 14.623   549.8497 5.208e-13 ***
## cubic        0.0     0.0     1 26.656     0.0084    0.9276    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb134"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model2lmer</span>, type <span class="op">=</span> <span class="st">'III'</span>, ddf <span class="op">=</span> <span class="st">'Ken'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Type III Analysis of Variance Table with Kenward-Roger's method
##           Sum Sq Mean Sq NumDF DenDF    F value    Pr(&gt;F)    
## linear    3731.4  3731.4     1    13 10641.3242 &lt; 2.2e-16 ***
## quadratic  192.8   192.8     1    13   549.8497 5.059e-12 ***
## cubic        0.0     0.0     1    13     0.0084    0.9283    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb136"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model3lmer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lmerTest/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">linear</span><span class="op">+</span><span class="va">quadratic</span> <span class="op">+</span> <span class="op">(</span><span class="va">linear</span><span class="op">+</span><span class="va">quadratic</span> <span class="op">|</span> <span class="va">Seed</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">Loblolly</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model3lmer</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite's method [
## lmerModLmerTest]
## Formula: height ~ linear + quadratic + (linear + quadratic | Seed)
##    Data: Loblolly
## 
## REML criterion at convergence: 211.8
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.84245 -0.45925 -0.07456  0.69006  1.78263 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr       
##  Seed     (Intercept)  2.045   1.4301              
##           linear      43.154   6.5692    0.92      
##           quadratic    7.338   2.7089   -0.81 -0.51
##  Residual              0.350   0.5916              
## Number of obs: 84, groups:  Seed, 14
## 
## Fixed effects:
##             Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept)  32.3644     0.3876  13.0017   83.50  &lt; 2e-16 ***
## linear      186.4457     1.8527  13.0449  100.64  &lt; 2e-16 ***
## quadratic   -21.8466     0.9350  14.5761  -23.37 5.84e-13 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Correlation of Fixed Effects:
##           (Intr) linear
## linear     0.858       
## quadratic -0.617 -0.372</code></pre>
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model3lmer</span>, type <span class="op">=</span> <span class="st">'III'</span>, ddf <span class="op">=</span> <span class="st">'lme4'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
##           npar Sum Sq Mean Sq F value
## linear       1 3434.6  3434.6 9812.68
## quadratic    1  191.1   191.1  545.96</code></pre>
<div class="sourceCode" id="cb140"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model3lmer</span>, type <span class="op">=</span> <span class="st">'III'</span>, ddf <span class="op">=</span> <span class="st">'Satt'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Type III Analysis of Variance Table with Satterthwaite's method
##           Sum Sq Mean Sq NumDF  DenDF  F value    Pr(&gt;F)    
## linear    3544.8  3544.8     1 13.045 10127.45 &lt; 2.2e-16 ***
## quadratic  191.1   191.1     1 14.576   545.96  5.84e-13 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb142"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model3lmer</span>, type <span class="op">=</span> <span class="st">'III'</span>, ddf <span class="op">=</span> <span class="st">'Ken'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Type III Analysis of Variance Table with Kenward-Roger's method
##           Sum Sq Mean Sq NumDF DenDF  F value    Pr(&gt;F)    
## linear    3544.8  3544.8     1    13 10127.45 &lt; 2.2e-16 ***
## quadratic  191.1   191.1     1    13   545.96 5.293e-12 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb144"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model3lmer</span>, <span class="va">model2lmer</span><span class="op">)</span></span></code></pre></div>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: Loblolly
## Models:
## model3lmer: height ~ linear + quadratic + (linear + quadratic | Seed)
## model2lmer: height ~ linear + quadratic + cubic + (linear + quadratic + cubic | Seed)
##            npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)
## model3lmer   10 234.49 258.80 -107.24   214.49                     
## model2lmer   15 243.71 280.17 -106.86   213.71 0.7787  5     0.9784</code></pre>
<p>As an alternative to Chi-squared/F-based tests performed using NLME or lmerTest, we provide a bootstrap-based analysis using bootMer. The downside of bootMer is that it is slow due to the need to refit the linear mixed model for each bootstrap simulation. Below we perform 100 such bootstrap simulations of model2—which is not enough for precise answers—but it is enough to get a good idea that the cubic term is ignorable and that the other fixed effects are significant.</p>
<div class="sourceCode" id="cb147"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fun</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">model</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="co">#booted &lt;- bootMer(model2lmer, fun, 100, type = 'parametric')</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">boot</span><span class="op">)</span></span>
<span><span class="co">#boot.ci(booted, conf = 0.95, type = 'basic', index = 1)</span></span>
<span><span class="co">#boot.ci(booted, conf = 0.95, type = 'basic', index = 2)</span></span>
<span><span class="co">#boot.ci(booted, conf = 0.95, type = 'basic', index = 3)</span></span>
<span><span class="co">#boot.ci(booted, conf = 0.95, type = 'basic', index = 4)</span></span></code></pre></div>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="poisson-regression.html"><span class="header-section-number">3</span> Poisson Regression</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-mixed-models"><span class="header-section-number">4</span> Linear Mixed Models</a></li>
<li>
<a class="nav-link" href="#anova-with-random-factors"><span class="header-section-number">4.1</span> ANOVA with random factors</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#strength-of-metallic-bonds"><span class="header-section-number">4.1.1</span> Strength of metallic bonds</a></li>
<li><a class="nav-link" href="#machine-productivity"><span class="header-section-number">4.1.2</span> Machine productivity</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#a-general-linear-mixed-model"><span class="header-section-number">4.2</span> A general linear mixed model</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#reml---frequentist-approach"><span class="header-section-number">4.2.1</span> REML - frequentist approach</a></li>
<li><a class="nav-link" href="#reml---bayesian-approach"><span class="header-section-number">4.2.2</span> REML - Bayesian approach</a></li>
<li><a class="nav-link" href="#predicting-random-effects-and-responses"><span class="header-section-number">4.2.3</span> Predicting random effects and responses</a></li>
<li><a class="nav-link" href="#example-fitting-a-linear-mixed-model-to-loblolly-pines-data"><span class="header-section-number">4.2.4</span> Example: Fitting a linear mixed model to Loblolly pines data</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#model-diagnostics"><span class="header-section-number">4.3</span> Model diagnostics</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#model-diagnostics-for-loblolly-pines-data"><span class="header-section-number">4.3.1</span> Model diagnostics for Loblolly pines data</a></li></ul>
</li>
<li>
<a class="nav-link" href="#inference-for-fixed-effects-random-effects-and-model-comparisons"><span class="header-section-number">4.4</span> Inference for fixed effects, random effects, and model comparisons</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#inference-on-fixed-effects-for-loblolly-pines-data"><span class="header-section-number">4.4.1</span> Inference on fixed effects for Loblolly pines data</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>GLMM</strong>" was written by Nick Syring. It was last built on 2023-02-14.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
